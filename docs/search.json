[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Car Collion within Montgomery County",
    "section": "",
    "text": "1 Introduction\n\n\nCode\nlibrary(tidyverse)\nlibrary(ggplot2)\n\nnumber_of_casualties &lt;- read_csv(\"data/Number_of_casualties_usa.csv\")\n\nggplot(number_of_casualties %&gt;%\n         filter(Year &gt;= 2005)) +\n  geom_col(aes(x = Year, y = Deaths), fill = \"#CC0000\", color = \"black\") +\n  geom_text(aes(x = Year, y = Deaths, label = Deaths), \n            vjust = -0.5, color = \"black\", size = 3) +  # Adjust vjust and size as needed\n  scale_x_continuous(breaks = seq(2005, 2021, 1)) +\n  labs(title = \"Number of Deaths from car accidents in the USA\",\n       subtitle = \"From 2005 to 2021\",\n       caption = \"Source: https://www.iihs.org/topics/fatality-statistics/detail/yearly-snapshot\")\n\n\n\n\n\nOur data visualization project delves into the complex and painful landscape of car accidents. The choice of exploring car accidents stems from the societal impact and safety considerations associated with road incidents. over 30,000 people are killed every year from car accidents in the USA. Just in 2022 almost 43,000 people in the USA died in car accidents*1. Understanding the underlying factors contributing to accidents can provide policy makers insights and key action items to help reduce the number and or severity of accidents. By leveraging data visualization techniques, we intend to unravel hidden trends and relationships that could inform policymakers, law enforcement, and the community at large.\n*1 source link\n*2 Graph data source link\nThe dataset we are using encompasses diverse attributes, ranging from temporal details like “Crash Date/Time” to factors such as “Hit/Run,” “Weather,” and “Road Condition.” This comprehensive dataset, sourced from the Public-Safety website of the Montgomery County, serves as a valuable resource for understanding the dynamics of vehicular incidents.\nOur goal in this project can be divided into three parts. In each part we will answer some guiding question.\n\n1.0.0.1 Part 1: Time Series Analysis\n\nWhat temporal trends or seasonality can be identified in the collision data?\nAre there variations in accident frequencies across different months, days of the week, or hours of the day?\nHow do holidays impact the frequency of accidents? (that is - do weeks with holidays tend to have different frequency of accidents)\n\n\n\n1.0.0.2 Part 2: Hit-and-Run Incidents:\n\nWhat correlations exist between various features and the occurrence of hit-and-run accidents?\nCan insights derived from the dataset offer recommendations for mitigating hit-and-run incidents?\n\n\n\n1.0.0.3 Part 3: Geospatial Exploration:\n\nCan we identify specific roads with a higher concentration of accidents, and what common attributes do they share?\nAre there geographical patterns unique to “regular” accidents versus “Hit and Run” incidents?\n\nTo conclude, our project not only aims to visualize the data but also to provide meaningful interpretations that contribute to the broader topic of road safety and accident prevention. For readers unfamiliar with the subject, our visualizations and analyses will offer an accessible entry point into the multifaceted world of car accidents and their implications."
  },
  {
    "objectID": "data.html#description",
    "href": "data.html#description",
    "title": "2  Data",
    "section": "2.1 Description",
    "text": "2.1 Description\nIn class, we were introduced to multiple plots and we are going to utilize them to drive insightful factors associating to higher number of collisions. Some of the interesting columns we wish to explore are “Crash Date/Time” to see if we can spot some trend or seasonality in the collision data based on the days of the week, hours in the day, etc. Similarly we want to use the geographical data to spot specific trends. Moreover, we will also study the quality of the roads or the configuration of the roads (whether it is curved or not, whether it is a two-way road or a single). Further the weather conditions will reveal some important trend. Some other paths to explore might be the “At Fault” column that describe whether the driver is at fault in the accident or a non-motorist. And the type of accidents thanks to “First Harmful Event”. Hence, our data offers various paths to explore, each potentially yielding distinct insights into car accidents.\nOverall, our goal is to identify combinations of features that could elevate the risk of collisions. This information can then provide policymakers with valuable insights to implement meaningful changes or restrictions on the roads."
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.3 Missing value analysis",
    "text": "2.3 Missing value analysis\nIn this part we analyze the missing values in the data and conduct some pre-processing to it.\n\n\nCode\ndata_crash &lt;- read_csv(\"data/Crash_Reporting_-_Incidents_Data.csv\", col_types = cols('Local Case Number' = col_character())) # the 2nd column contains string and not number that's why we specify it.\ndata_crash &lt;- rename(data_crash, \"Hit_Run\" = `Hit/Run`) \ndata_crash &lt;- rename(data_crash,\"Crash_Date_Time\" = `Crash Date/Time`)\n\n#rename(\"Crash_Date_Time\" = `Crash_Date/Time`)\n\n### Preprocess:\nnew_col_names &lt;- colnames(data_crash)\n# Replace spaces and dashes with underscores\nnew_col_names &lt;- gsub(\" \", \"_\", new_col_names)\nnew_col_names &lt;- gsub(\"-\", \"_\", new_col_names)\ncolnames(data_crash) &lt;- new_col_names\n\ndata_crash |&gt; select(-c(Local_Case_Number, Agency_Name)) |&gt; head()\n\n\n# A tibble: 6 × 42\n  Report_Number ACRS_Report_Type   Crash_Date_Time Hit_Run Route_Type Mile_Point\n  &lt;chr&gt;         &lt;chr&gt;              &lt;chr&gt;           &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;\n1 MCP2686006F   Property Damage C… 06/30/2023 10:… No      &lt;NA&gt;            NA   \n2 MCP3230004G   Property Damage C… 06/30/2023 08:… No      County           1.42\n3 MCP12600013   Injury Crash       06/29/2023 11:… No      Maryland …      11.3 \n4 DD55750030    Property Damage C… 07/01/2023 01:… Yes     Municipal…       0.07\n5 MCP3010008B   Property Damage C… 07/01/2023 12:… No      Other Pub…       0   \n6 MCP2667008J   Property Damage C… 06/30/2023 12:… No      County           0.73\n# ℹ 36 more variables: Mile_Point_Direction &lt;chr&gt;, Lane_Direction &lt;chr&gt;,\n#   Lane_Number &lt;dbl&gt;, Lane_Type &lt;chr&gt;, Number_of_Lanes &lt;dbl&gt;, Direction &lt;chr&gt;,\n#   Distance &lt;dbl&gt;, Distance_Unit &lt;chr&gt;, Road_Grade &lt;chr&gt;, NonTraffic &lt;chr&gt;,\n#   Road_Name &lt;chr&gt;, Cross_Street_Type &lt;chr&gt;, Cross_Street_Name &lt;chr&gt;,\n#   Off_Road_Description &lt;chr&gt;, Municipality &lt;chr&gt;, Related_Non_Motorist &lt;chr&gt;,\n#   At_Fault &lt;chr&gt;, Collision_Type &lt;chr&gt;, Weather &lt;chr&gt;,\n#   Surface_Condition &lt;chr&gt;, Light &lt;chr&gt;, Traffic_Control &lt;chr&gt;, …\n\n\n\nWe saw there are columns (for example: Municipality) with values like: “N/A” which we would like to transform into explicit NA\n\n\n\nCode\n# Function to replace \"N/A\" with explicit NA in a vector\nreplace_na &lt;- function(x) {\n  x[x == \"N/A\"] &lt;- NA\n  return(x)\n}\n\n# Apply the function to each column of the data_crash frame\ndata_crash &lt;- as_tibble(lapply(data_crash, replace_na))"
  },
  {
    "objectID": "data.html#analyzing-nas",
    "href": "data.html#analyzing-nas",
    "title": "2  Data",
    "section": "2.4 Analyzing NAs",
    "text": "2.4 Analyzing NAs\nLet’s analyze the NAs in the different columns - how many NAs we have in each one of the columns?\n\n\nCode\n## PLot the number of NAs for each column\n\nb &lt;- apply(data_crash, 2, function(c) sum(is.na(c)))\ntibble_nas &lt;- tibble(column_name = names(b), number_of_NA = b)\ntibble_nas |&gt; arrange(desc(number_of_NA))\n\n\n# A tibble: 44 × 2\n   column_name                  number_of_NA\n   &lt;chr&gt;                               &lt;int&gt;\n 1 Non_Motorist_Substance_Abuse        91406\n 2 Related_Non_Motorist                90311\n 3 Lane_Type                           86261\n 4 Municipality                        85404\n 5 Off_Road_Description                83479\n 6 Fixed_Oject_Struck                  75409\n 7 Second_Harmful_Event                71550\n 8 Intersection_Area                   69682\n 9 Intersection_Type                   48164\n10 Junction                            25588\n# ℹ 34 more rows\n\n\nCode\nggplot(tibble_nas |&gt; filter(number_of_NA &gt;0 ))+\n  geom_col(mapping = aes(y=reorder(column_name,number_of_NA), x = number_of_NA),\n               fill = \"cornflowerblue\", color = \"black\") +\n  labs(title = \"Number of NAs in the data columns\",\n       subtitle = \"Showing only columns with number of NAs &gt; 0\",\n       y = 'Column name')\n\n\n\n\n\n\n\nCode\npaste0(\"Number of columns with at least 1 NA = \", tibble_nas |&gt; filter(number_of_NA &gt; 0) |&gt; nrow())\n\n\n[1] \"Number of columns with at least 1 NA = 32\"\n\n\nCode\npaste0(\"Number of columns without any NAs = \", tibble_nas |&gt; filter(number_of_NA == 0) |&gt; nrow())\n\n\n[1] \"Number of columns without any NAs = 12\"\n\n\n\nThere are some columns that have “too many” NA values - those are columns that more than 45% of the values in the column has an NA value. Those columns may be less relevant for our analysis. Let’s see how many such columns we have and what are those columns:\n\n\n\nCode\ncolumns_with_too_many_nas &lt;- tibble_nas|&gt; filter(number_of_NA&gt;0) |&gt; arrange(number_of_NA) |&gt; filter(number_of_NA &gt; 45000)\ncolumns_with_too_many_nas\n\n\n# A tibble: 9 × 2\n  column_name                  number_of_NA\n  &lt;chr&gt;                               &lt;int&gt;\n1 Intersection_Type                   48164\n2 Intersection_Area                   69682\n3 Second_Harmful_Event                71550\n4 Fixed_Oject_Struck                  75409\n5 Off_Road_Description                83479\n6 Municipality                        85404\n7 Lane_Type                           86261\n8 Related_Non_Motorist                90311\n9 Non_Motorist_Substance_Abuse        91406\n\n\n\nThere are 9 columns with “too many” NA rows (more than 45% of the rows):\n\nWe will remove those columns :\n\n\nCode\ndata_crash &lt;- dplyr::select(data_crash,-as.vector(columns_with_too_many_nas$column_name))\n\n\n\nFurther, there are many columns with NA values that mostly overlap each other (if there is NA in one of those columns it also appears in the other ones), The following code reflects that fact –&gt; if we filter the NAs from the column: Cross-Street Type –&gt; we can observe that the number of columns with NAs reduces significantly.\n\n\n\nCode\nfiltered_data_crash &lt;- data_crash[!is.na(data_crash$Cross_Street_Type),]\n\n\nb &lt;- apply(filtered_data_crash, 2, function(c) sum(is.na(c)))\ntibble_nas &lt;- tibble(column_name = names(b), number_of_NA = b)\ntibble_nas_filtered_data_crash &lt;- tibble_nas\n\n\nggplot(tibble_nas |&gt; filter(number_of_NA &gt;0 ))+\n  geom_col(mapping = aes(y=reorder(column_name,number_of_NA), x = number_of_NA),\n           fill = \"cornflowerblue\", color = \"black\") +\n  labs(title = \"Number of NAs in the data_crash columns\",\n       subtitle = \"Showing only columns with number of NAs &gt; 0\",\n       y = 'Column name')\n\n\n\n\n\nFor now we won’t deal with those NAs. Later in the project we would choose the specific columns to analyze together and then we will decide on the best method to deal with the NAs in those columns."
  },
  {
    "objectID": "data.html#repartition-of-the-nas-in-between-columns",
    "href": "data.html#repartition-of-the-nas-in-between-columns",
    "title": "2  Data",
    "section": "2.5 Repartition of the NAs in between columns",
    "text": "2.5 Repartition of the NAs in between columns\nWe want to get a list of columns that has the same “NA” pattern:\n\n\nCode\nb &lt;- apply(data_crash, 2, function(c) sum(is.na(c)))\ntibble_nas_data_crash &lt;- tibble(column_name = names(b), number_of_NA = b)\n\n#Compare the 2 lists, the one with all the column with less that 1000 NAs and the lists with the same conditions but after removing all the NAs row in the column \"Cross-Street Type\"\na &lt;- tibble_nas_data_crash |&gt; filter(number_of_NA&lt;1000)\nb &lt;- tibble_nas_filtered_data_crash |&gt; filter(number_of_NA&lt;1000)\n\n# Get the name of the column which are not in common in the 2 previous list\ndifference_both_ways &lt;- union(setdiff(a$column_name, b$column_name), setdiff(b$column_name, a$column_name))\nprint(difference_both_ways)\n\n\n [1] \"Route_Type\"           \"Mile_Point\"           \"Mile_Point_Direction\"\n [4] \"Lane_Direction\"       \"Direction\"            \"Distance\"            \n [7] \"Distance_Unit\"        \"Road_Grade\"           \"Road_Name\"           \n[10] \"Cross_Street_Type\"    \"Cross_Street_Name\"    \"Road_Alignment\"      \n\n\nWe want to use the plot_missing function for redav package to see the NAs pattern regarding the columns that we suspect has NAs in the same rows:\n\n\nCode\nredav::plot_missing(data_crash |&gt;dplyr::select(difference_both_ways,))\n\n\n\n\n\nUsing the plot_missing function, we can clearly see that those columns indeed has NAs in the same rows. We can conclude that their NAs are correlated.\nFurther, we will take one of those columns: Cross_Street_Type and use it as a representative of the 12 columns group and then see if there is any pattern between the NAs of the other columns:\n\n\nCode\nb &lt;- apply(data_crash, 2, function(c) sum(is.na(c)))\ntibble_nas &lt;- tibble(column_name = names(b), number_of_NA = b)\n\n\ncolumns_with_na &lt;- tibble_nas |&gt; filter(number_of_NA&gt;500) \n\ncolumns_with_na &lt;- columns_with_na$column_name\n\ndifferences &lt;- union(setdiff(columns_with_na, difference_both_ways), setdiff(difference_both_ways, columns_with_na))\n\ndifferences &lt;- c(differences, \"Cross_Street_Type\")\nprint(differences)\n\n\n [1] \"Weather\"                \"Surface_Condition\"      \"Light\"                 \n [4] \"Traffic_Control\"        \"Driver_Substance_Abuse\" \"First_Harmful_Event\"   \n [7] \"Junction\"               \"Road_Condition\"         \"Road_Division\"         \n[10] \"Cross_Street_Type\"     \n\n\nCode\nredav::plot_missing(data_crash |&gt;dplyr::select(differences,))\n\n\n\n\n\nOne can see that there is no common pattern between all the NAs for these 10 columns.\nIn conclusion, for all the columns in the array ‘difference_both_ways’ we can deal with the NAs in the same way in the future. However, for the other columns which still has a lot of NAs like Weather or Traffic Control, we need to be more careful when removing the NAs because we could end up with very few rows in the data set. We will take care of them on a case-by-case basis.\n\n2.5.0.1 Saving the updated data so we can read it in the “results” tab\n\n\nCode\nwrite_csv2(data_crash, \"data/data_crash.csv\")\n\n\n\n\n2.5.1 Holiday data\nWe understood there could be some special significant to some days during the year - those are the holidays in the american calendar. We assume the number of car accident might be influenced by the fact there is a holiday (and maybe more/less people will drive and/or people might be more likely to drink and drive or act in a more dangerous/safe manner)\nTo get the dates of these holidays we used a dataset from Microsoft Azure that we downloaded using Python Visit Microsoft Azure Open Datasets. We filtered the relevant rows for our study (took dates between 2015 and 2023) and created the holiday_data data frame.\n\n\nCode\nholiday_data &lt;- readr::read_csv(\"data/holiday_dates.csv\")\n\n\nRows: 69557 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): countryOrRegion, holidayName, normalizeHolidayName, countryRegionCode\nlgl  (1): isPaidTimeOff\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nholiday_data &lt;- holiday_data |&gt; filter(countryOrRegion == \"United States\") |&gt; select(c(normalizeHolidayName,isPaidTimeOff, date)) \n\nholiday_data$is_holiday &lt;- \"Yes\"\nholiday_data &lt;- holiday_data |&gt; rename(\"Holiday\" = \"normalizeHolidayName\")"
  },
  {
    "objectID": "results.html#spatial-representation",
    "href": "results.html#spatial-representation",
    "title": "3  Results",
    "section": "4.3 Spatial Representation",
    "text": "4.3 Spatial Representation\n\n\nCode\n# Sample the data so that we do not have too much data ploted on the map\n\n\n# dt_sampled &lt;-# sample_n(as.data.frame(data_crash), 4000) %&gt;%\n#   \n#   # # filter(Hit_Run == 'Yes')\n#   # filter(Number_of_Lanes == 19) %&gt;%\n#   #sample_n(4000)\n#   filter(data_crash$Road_Name == top10)\ndt_sampled &lt;- data_crash %&gt;%\n  filter(Road_Name %in% top10)%&gt;%\n  sample_n(2000)\n\n#dt_sampled &lt;- sample_n(as.data.frame(data_crash), 4000)\n  # rename(Hit_Run = 'Hit/Run') %&gt;%\n  # # filter(Hit_Run == 'Yes')\n  # filter(Number_of_Lanes == 19) %&gt;%\n\n\n\n\n# Display the random sample\n#print(dt_sampled)\n\n\n\n\nCode\n# Spatial data\n\n# \n leaflet(dt_sampled) %&gt;%\n#   addTiles() %&gt;% \n#   addHeatmap(\n#   lat = ~Latitude,\n#   lng = ~Longitude,\n#   blur = 15,  # Adjust the blur parameter\n#   radius = 10)  # Adjust the radius parameter\n  addMarkers(lng = ~Longitude, lat = ~Latitude, popup = \"Marker\")\n\n\n\n\n\n\nComment : We can see from the map multiple ouliers, all the crash data should be in the Montgomery County so every data outside of this area can be considered as outliers. Maybe when the localisation was added to the police report some numbers were mistaken. *Should we remove all of them ?"
  },
  {
    "objectID": "results.html#time-series",
    "href": "results.html#time-series",
    "title": "3  Results",
    "section": "3.1 Time Series",
    "text": "3.1 Time Series\n\n\nCode\n#dt_temporal &lt;- data_crash[,]\n\ndt_temporal &lt;- dplyr::select(data_crash,c(\"Crash_Date_Time\",\"Weather\", \"Hit_Run\",\n                       \"First_Harmful_Event\", \"At_Fault\"))\n\n# dt_temporal &lt;- left_join(dt_temporal, holiday_data, by = c(\"Crash_Date\" = \"date\"))\n# \n# dt_temporal &lt;- mutate(dt_temporal, is_holiday = ifelse(is.na(is_holiday), \"No\", is_holiday))\n\n\n\nhead(dt_temporal)\n\n\n# A tibble: 6 × 5\n  Crash_Date_Time        Weather Hit_Run First_Harmful_Event At_Fault\n  &lt;chr&gt;                  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;               &lt;chr&gt;   \n1 06/30/2023 10:55:00 PM CLEAR   No      FIXED OBJECT        DRIVER  \n2 06/30/2023 08:00:00 PM CLEAR   No      OTHER VEHICLE       DRIVER  \n3 06/29/2023 11:53:00 AM CLEAR   No      FIXED OBJECT        DRIVER  \n4 07/01/2023 01:48:00 AM CLOUDY  Yes     PARKED VEHICLE      UNKNOWN \n5 07/01/2023 12:52:00 PM CLEAR   No      PARKED VEHICLE      DRIVER  \n6 06/30/2023 12:00:00 PM CLEAR   No      OTHER VEHICLE       DRIVER  \n\n\n\n\nCode\n#Separate time and Date\n\ndt_temporal$\"Crash_Date_Time\" &lt;- as.POSIXct(dt_temporal$\"Crash_Date_Time\", format = \"%m/%d/%Y %I:%M:%S %p\", tz = \"America/New_York\")\n\ndt_temporal$Crash_Date &lt;- as.Date(dt_temporal$\"Crash_Date_Time\", tz = \"America/New_York\")\n\n#I have a problem with the hours it doesn't show up well\ndt_temporal$Crash_Time &lt;- format(dt_temporal$\"Crash_Date_Time\", \"%H:%M:%S\")\ndt_temporal\n\n\n# A tibble: 95,584 × 7\n   Crash_Date_Time     Weather Hit_Run First_Harmful_Event At_Fault Crash_Date\n   &lt;dttm&gt;              &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;               &lt;chr&gt;    &lt;date&gt;    \n 1 2023-06-30 22:55:00 CLEAR   No      FIXED OBJECT        DRIVER   2023-06-30\n 2 2023-06-30 20:00:00 CLEAR   No      OTHER VEHICLE       DRIVER   2023-06-30\n 3 2023-06-29 11:53:00 CLEAR   No      FIXED OBJECT        DRIVER   2023-06-29\n 4 2023-07-01 01:48:00 CLOUDY  Yes     PARKED VEHICLE      UNKNOWN  2023-07-01\n 5 2023-07-01 12:52:00 CLEAR   No      PARKED VEHICLE      DRIVER   2023-07-01\n 6 2023-06-30 12:00:00 CLEAR   No      OTHER VEHICLE       DRIVER   2023-06-30\n 7 2023-06-30 18:00:00 CLEAR   Yes     PARKED VEHICLE      DRIVER   2023-06-30\n 8 2023-06-29 13:03:00 CLEAR   No      FIXED OBJECT        DRIVER   2023-06-29\n 9 2023-06-26 16:26:00 CLEAR   No      OTHER VEHICLE       DRIVER   2023-06-26\n10 2023-06-29 12:59:00 CLEAR   No      OFF ROAD            DRIVER   2023-06-29\n# ℹ 95,574 more rows\n# ℹ 1 more variable: Crash_Time &lt;chr&gt;\n\n\nCode\n#ggplot(dt_temporal, aes(x = as.factor(Crash_week))) +\n       #stat_count() +\n       #labs(title='Number of car crash per weeks')\n\n\n\n3.1.1 Preprocessing for the df_temporal\n\n\nCode\n### add some \"date slicers\" columns\ndt_temporal$Week_day &lt;- weekdays(dt_temporal$Crash_Date)\ndt_temporal$Month &lt;-  months(dt_temporal$Crash_Date)\ndt_temporal$Year &lt;-  year(dt_temporal$Crash_Date)\ndt_temporal$first_day_of_month &lt;- as.Date(format(dt_temporal$Crash_Date, \"%Y-%m-01\"))\n\nlibrary(hms)\n\n\n\nAttaching package: 'hms'\n\n\nThe following object is masked from 'package:lubridate':\n\n    hms\n\n\nCode\ndt_temporal$Crash_Time &lt;- as_hms(dt_temporal$Crash_Time)\ndt_temporal$Crash_Hour &lt;- hour(dt_temporal$Crash_Time) #Crash hour\n\n\n### Transform some colkumns to factors\ndt_temporal &lt;- mutate(dt_temporal, Week_day = factor(Week_day,\n                                             levels = c(\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\")))\n\ndt_temporal$Month &lt;- factor(dt_temporal$Month, \n                          levels = c(\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\"July\", \"August\", \"September\", \"October\", \"November\", \"December\"),)\n\n### arrange the data by date\ndt_temporal &lt;- dt_temporal |&gt; arrange(Crash_Date)\n\ndt_temporal_month &lt;- dt_temporal |&gt; group_by(Month, first_day_of_month, Week_day) |&gt; summarise(total_accidents = n())\n\n\n`summarise()` has grouped output by 'Month', 'first_day_of_month'. You can\noverride using the `.groups` argument.\n\n\nCode\ndt_temporal_Year_month &lt;- dt_temporal |&gt; group_by(Year, Month, first_day_of_month, Week_day) |&gt; summarise(total_accidents = n())\n\n\n`summarise()` has grouped output by 'Year', 'Month', 'first_day_of_month'. You\ncan override using the `.groups` argument.\n\n\nCode\n### create a ts object\nfirst_date_in_data &lt;- min(dt_temporal$first_day_of_month)\nlast_date_in_data &lt;- max(dt_temporal$first_day_of_month)\n\n\n\n\nCode\nstart_date = min(dt_temporal$Crash_Date)\nend_date = max(dt_temporal$Crash_Date)\n\ndate_sequence &lt;- seq(as.Date(\"2014-12-28\"), end_date, by = \"week\")\ndt_temporal$Crash_week &lt;- cut(dt_temporal$Crash_Date, breaks = c(date_sequence, Inf), labels = as.factor(date_sequence), include.lowest = TRUE)\n\ndt_temporal_red &lt;- dt_temporal %&gt;%\n  filter(Crash_Date &gt; as.Date(\"2013\", format = '%Y')) %&gt;%\n  group_by(Crash_week) %&gt;%\n  mutate(Count_week = n()) %&gt;%\n  arrange(Crash_week)\n\n#Create a new table to remove the iteration where there are multiple time the same combination for the columns Crash_week and Count_week.\ndt_temporal_week &lt;- dt_temporal_red %&gt;%\n  distinct(Crash_week, Count_week, .keep_all = TRUE)%&gt;%\n  mutate(Crash_week = as.Date(Crash_week, format = \"%Y-%m-%d\")) %&gt;%\n  mutate(Crash_month = month(Crash_week))\n#   \n#   mutate(is_holiday = ifelse(Week_with_holiday %in% weeks_with_holiday$Week_with_holiday, \"Yes\", is_holiday)) %&gt;%\n#   select(-Week_with_holiday)\n\n\nggplot(dt_temporal_week, aes(x = Crash_week, y = Count_week)) +\n  geom_line(aes(group=1)) + #because we grouped earlier by Crash_week we need now to specify that we treat all the data as one group.\n  geom_point() +\n  labs(title='Number of car crash per weeks')+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n# Set breaks to 1 month interval\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") \n\n\n\n\n\nCode\n  #scale_x_date(date_breaks = \"1 month\", date_labels = \"%b %Y\")  \n\n\n\n\nCode\n# Create a new column for the week of the year\n# Step 1: Create a data frame with all days in the year\nall_days &lt;- data.frame(date = seq(min(dt_temporal$Crash_Date), max(dt_temporal$Crash_Date), by = \"days\"))\n\n# Step 2: Merge the data frames based on the week\nmerged_df &lt;- inner_join(all_days, holiday_data, by = \"date\")\n\n# Step 3: Create a new column \"Is_Holiday\" based on the merging results\nmerged_df$is_holiday &lt;- ifelse(!is.na(merged_df$is_holiday), \"Yes\", \"No\")\nmerged_dy_for_temporal_day &lt;- merged_df\n\nmerged_df$first_day_of_week_new &lt;- floor_date(merged_df$date, \"week\")\nmerged_df$weekday1 &lt;- weekdays(merged_df$first_day_of_week)\n\nresult_df &lt;- merged_df %&gt;%\n  group_by(first_day_of_week_new) %&gt;%\n  summarise(is_holiday = if (\"Yes\" %in% is_holiday) \"Yes\" else \"No\")\n\n\n\n\nCode\ndt_temporal_week &lt;- left_join(dt_temporal_week, result_df, by = c(\"Crash_week\" = \"first_day_of_week_new\"))\n\ndt_temporal_week &lt;- mutate(dt_temporal_week, is_holiday = ifelse(is.na(is_holiday), \"No\", is_holiday))\n\n\nggplot(dt_temporal_week, aes(x = Crash_week, y = Count_week)) +\n  geom_line(aes(group=1)) + #because we grouped earlier by Crash_week we need now to specify that we treat all the data as one group.\n  geom_point(aes(color = is_holiday)) +\n  labs(title='Number of car crash per weeks')+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n# Set breaks to 1 month interval\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") \n\n\n\n\n\nCode\n  #scale_x_date(date_breaks = \"1 month\", date_labels = \"%b %Y\")  \n\n\nComment : We can visualize thanks to the time series representation the Covid crisis which lead to a reduction of car accident in 2020 since less cars were on the roads. Since then, the average number of accidents is a bit lower than pre-covid."
  },
  {
    "objectID": "results.html#show-the-same-plot-by-days",
    "href": "results.html#show-the-same-plot-by-days",
    "title": "3  Results",
    "section": "3.2 Show the same plot by days",
    "text": "3.2 Show the same plot by days\n\n\nCode\ndt_temporal_day &lt;- dt_temporal |&gt; group_by(Year, Month, Crash_Date) |&gt; summarise(total_crash = n())\n\n\n`summarise()` has grouped output by 'Year', 'Month'. You can override using the\n`.groups` argument.\n\n\nCode\ndt_temporal_day &lt;- left_join(dt_temporal_day, merged_dy_for_temporal_day, by = c(\"Crash_Date\"= \"date\"))\n\n\n\nggplot(dt_temporal_day |&gt; filter(Year == 2019), aes(x = Crash_Date, y = total_crash)) +\n  geom_line(aes(group=1)) + #because we grouped earlier by Crash_Date we need now to specify that we treat all the data as one group.\n  geom_point(aes(color = is_holiday)) +\n  labs(title='Number of car crash per weeks')+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n# Set breaks to 1 month interval\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") \n\n\n\n\n\nCode\n  #scale_x_date(date_breaks = \"1 month\", date_labels = \"%b %Y\")  \n\n\n\n\nCode\ndt_temporal_day |&gt;  group_by(Year) %&gt;%\n  slice(which.max(total_crash))\n\n\n# A tibble: 9 × 6\n# Groups:   Year [9]\n   Year Month     Crash_Date total_crash holiday is_holiday\n  &lt;dbl&gt; &lt;fct&gt;     &lt;date&gt;           &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;     \n1  2015 November  2015-11-10          71 &lt;NA&gt;    &lt;NA&gt;      \n2  2016 November  2016-11-30          71 &lt;NA&gt;    &lt;NA&gt;      \n3  2017 December  2017-12-15          59 &lt;NA&gt;    &lt;NA&gt;      \n4  2018 November  2018-11-05          65 &lt;NA&gt;    &lt;NA&gt;      \n5  2019 October   2019-10-31          77 &lt;NA&gt;    &lt;NA&gt;      \n6  2020 January   2020-01-03          51 &lt;NA&gt;    &lt;NA&gt;      \n7  2021 September 2021-09-22          62 &lt;NA&gt;    &lt;NA&gt;      \n8  2022 March     2022-03-12          48 &lt;NA&gt;    &lt;NA&gt;      \n9  2023 February  2023-02-13          56 &lt;NA&gt;    &lt;NA&gt;      \n\n\nCode\na &lt;- dt_temporal_day |&gt; \n  group_by(Year) |&gt;\n  top_n(5, total_crash) #|&gt; filter(Month %in% c(\"January\"))\nggplot(a) +\n  geom_point(aes(x=Crash_Date, y=total_crash)) +\n  scale_y_continuous(limits = c(0,80)) +\n  scale_x_date(date_labels = \"%Y-%m-%d\", date_breaks = \"1 month\")+\n    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))\n\n\n\n\n\nCode\na |&gt; group_by(Month) |&gt; summarise(count=n()) #count(Month)\n\n\n# A tibble: 10 × 2\n   Month     count\n   &lt;fct&gt;     &lt;int&gt;\n 1 January       9\n 2 February      5\n 3 March         4\n 4 May           5\n 5 July          1\n 6 August        2\n 7 September     4\n 8 October       5\n 9 November     10\n10 December     11\n\n\nCode\n#holiday_data\n\n\n\n\nCode\ndt_temporal_day &lt;- mutate(dt_temporal_day,crash_day_no_year = format(Crash_Date, \"%m-%d\"))\n\nMonth_list &lt;-  c(\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\")\n\n##################################### data for d3 - mean crash per day over years\nc &lt;- dt_temporal_day |&gt; filter(Year!=2020 & Year&lt;2023)|&gt; group_by(Month, crash_day_no_year) |&gt; summarise(total_crash = mean(total_crash)) |&gt;  mutate(day_only = factor(substr(crash_day_no_year, 4, 5)))\n\n\n`summarise()` has grouped output by 'Month'. You can override using the\n`.groups` argument.\n\n\nCode\nwrite_csv(c, \"data/mean_crash_per_day_over_years.csv\")\n\n\n###########################################################\n### let's see how this graph should look like in d3:\nb &lt;- dt_temporal_day |&gt; filter(Year!=2020 & Year&lt;2023)|&gt; filter(Month %in%Month_list[1:7]) |&gt; group_by(Month, crash_day_no_year) |&gt; summarise(total_crash = mean(total_crash)) |&gt;  mutate(day_only = factor(substr(crash_day_no_year, 4, 5)))\n\n\n`summarise()` has grouped output by 'Month'. You can override using the\n`.groups` argument.\n\n\nCode\n# # Create the plot\n# ggplot(b, aes(x = crash_day_no_year, y = total_crash, color = Month)) +\n#   geom_point() +\n#   facet_grid(~Month)+\n#   labs(y = \"Total Crash\") \n\n  \n# Create the plot\nggplot(b, aes(x = day_only, y = total_crash, color = Month, group=Month)) +\n  geom_point() +\n  geom_line(alpha = 0.6)+\n  #facet_grid(Month~., scales = \"free_x\", space = \"free_x\") +\n  labs(y = \"Total Crash\") \n\n\n\n\n\nCode\n# \n# ggplot(b) +\n#   geom_point(aes(x=crash_day_no_year, y=total_crash)) +\n#   scale_y_continuous(limits = c(0,80)) +\n#   scale_x_date(date_labels = \"%Y-%m-%d\", date_breaks = \"1 month\")+\n#     theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))\n\n\nd =&gt; ({\n        Month: parseInt(d.Month),\n        crash_day_no_year: parseInt(d.crash_day_no_year),\n        total_crash: parse\n    })\n\n\nCode\nc\n\n\n# A tibble: 366 × 4\n# Groups:   Month [12]\n   Month   crash_day_no_year total_crash day_only\n   &lt;fct&gt;   &lt;chr&gt;                   &lt;dbl&gt; &lt;fct&gt;   \n 1 January 01-01                    19.7 01      \n 2 January 01-02                    25.3 02      \n 3 January 01-03                    30   03      \n 4 January 01-04                    29.9 04      \n 5 January 01-05                    27   05      \n 6 January 01-06                    30.4 06      \n 7 January 01-07                    29.1 07      \n 8 January 01-08                    33   08      \n 9 January 01-09                    31.1 09      \n10 January 01-10                    27.7 10      \n# ℹ 356 more rows\n\n\n\n\nCode\nggplot(dt_temporal_day |&gt; mutate(Year = as.factor(Year))) +\n  geom_boxplot(aes(x=Year, y=total_crash))\n\n\n\n\n\n\n\nCode\ndt_temporal_day |&gt;  group_by(Year) %&gt;%\n  summarise((mean(total_crash)))\n\n\n# A tibble: 9 × 2\n   Year `(mean(total_crash))`\n  &lt;dbl&gt;                 &lt;dbl&gt;\n1  2015                  31.4\n2  2016                  33.1\n3  2017                  33.2\n4  2018                  32.5\n5  2019                  32.0\n6  2020                  22.0\n7  2021                  25.6\n8  2022                  27.5\n9  2023                  27.9\n\n\n\n\nCode\ndt_temporal_day |&gt;  group_by(Year) %&gt;%\n  slice(which.min(total_crash))\n\n\n# A tibble: 9 × 7\n# Groups:   Year [9]\n   Year Month    Crash_Date total_crash holiday     is_holiday crash_day_no_year\n  &lt;dbl&gt; &lt;fct&gt;    &lt;date&gt;           &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;            \n1  2015 July     2015-07-01           8 Canada Day  Yes        07-01            \n2  2016 January  2016-01-23           2 &lt;NA&gt;        &lt;NA&gt;       01-23            \n3  2017 May      2017-05-29           9 &lt;NA&gt;        &lt;NA&gt;       05-29            \n4  2018 February 2018-02-07          13 &lt;NA&gt;        &lt;NA&gt;       02-07            \n5  2019 January  2019-01-01          10 New Year's… Yes        01-01            \n6  2020 April    2020-04-06           5 &lt;NA&gt;        &lt;NA&gt;       04-06            \n7  2021 March    2021-03-28           5 &lt;NA&gt;        &lt;NA&gt;       03-28            \n8  2022 January  2022-01-05           8 &lt;NA&gt;        &lt;NA&gt;       01-05            \n9  2023 November 2023-11-15           2 &lt;NA&gt;        &lt;NA&gt;       11-15            \n\n\n\n\nCode\nggplot(dt_temporal_day, aes(x = Crash_Date, y = total_crash)) +\n  geom_line(aes(group=1)) + #because we grouped earlier by Crash_Date we need now to specify that we treat all the data as one group.\n  geom_point(aes(color = is_holiday)) +\n  labs(title='Number of car crash per weeks')+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n# Set breaks to 1 month interval\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") \n\n\n\n\n\nCode\n  #scale_x_date(date_breaks = \"1 month\", date_labels = \"%b %Y\")\n\n\n\n3.2.1 Weather Condition\n\n\nCode\ndt_temporal &lt;- dt_temporal %&gt;%\n  filter(!Weather %in% c(\"OTHER\", \"UNKNOWN\")) %&gt;%\n  filter(!is.na(Weather))\n\ndt_temporal &lt;- dt_temporal %&gt;%\n  mutate(Weather = if_else(Weather %in% c(\"SNOW\", \"SLEET\",\"BLOWING SNOW\"), \"SNOW\", Weather)) %&gt;%\n  mutate(Weather = if_else(Weather %in% c(\"SEVERE WINDS\", \"WINTRY MIX\", \"BLOWING SAND, SOIL, DIRT\"), \"WIND\", Weather))%&gt;%\n  mutate(Condition = if_else(Weather %in% c(\"CLEAR\",\"CLOUDY\"),\"Good\",\"Bad\"))\n\ncolor_scale &lt;- c(\"RAINING\" = \"slateblue\", \"SNOW\" = \"whitesmoke\", \"CLOUDY\" = \"gray\", \"FOGGY\" =\"gray27\", \"WIND\"=\"seagreen4\", \"CLEAR\" =\"skyblue\")\n\ndt_temporal$Weather &lt;- reorder(dt_temporal$Weather, X= as.numeric(factor(dt_temporal$Weather,levels = c('CLEAR','CLOUDY','FOGGY','WIND','SNOW','RAINING'))))\n\nggplot(dt_temporal, aes(x = Condition, fill = Weather)) +\n  geom_bar() +\n  scale_fill_manual(values = color_scale)\n\n\n\n\n\nCode\n#ggplot(dt_temporal, aes(x= Weather))+\n#geom_bar()\n\n\nComment : One can see an asymmetry between the bad and good conditions. It seems that bad conditions does not necessarily imply a higher number of accidents. However to be sure about that we need to have the proportion of the number of days where the road conditions were good or not.\n\n\n3.2.2 Hours of the day\n\n\nCode\n# we only care about the hours not the minutes\ndt_temporal &lt;- dt_temporal %&gt;%\n  mutate(Crash_Time = paste0(substr(Crash_Time, start = 1, stop =2),'h')) \n\n\nggplot(dt_temporal, aes(x=Crash_Time))+\n  geom_bar()+\n  labs(x = 'Hours in the day',y = 'Number of Crash')\n\n\n\n\n\nComment : One can see that crash accidents occur more during the commute time especially the way back home between 15h to 17h.\n\n\n3.2.3 Type of Lane"
  },
  {
    "objectID": "results.html#roy",
    "href": "results.html#roy",
    "title": "3  Results",
    "section": "3.3 Roy",
    "text": "3.3 Roy\n\nRoy\n\n\nCode\ndata_crash |&gt; head()\n\n\n# A tibble: 6 × 35\n  Report_Number Local_Case_Number Agency_Name   ACRS_Report_Type Crash_Date_Time\n  &lt;chr&gt;                     &lt;dbl&gt; &lt;chr&gt;         &lt;chr&gt;            &lt;chr&gt;          \n1 MCP2686006F           230031339 Montgomery C… Property Damage… 06/30/2023 10:…\n2 MCP3230004G           230031335 Montgomery C… Property Damage… 06/30/2023 08:…\n3 MCP12600013           230031067 Montgomery C… Injury Crash     06/29/2023 11:…\n4 DD55750030            230031365 Rockville Po… Property Damage… 07/01/2023 01:…\n5 MCP3010008B           230034141 Montgomery C… Property Damage… 07/01/2023 12:…\n6 MCP2667008J           230031246 Montgomery C… Property Damage… 06/30/2023 12:…\n# ℹ 30 more variables: Hit_Run &lt;chr&gt;, Route_Type &lt;chr&gt;, Mile_Point &lt;dbl&gt;,\n#   Mile_Point_Direction &lt;chr&gt;, Lane_Direction &lt;chr&gt;, Lane_Number &lt;dbl&gt;,\n#   Number_of_Lanes &lt;dbl&gt;, Direction &lt;chr&gt;, Distance &lt;dbl&gt;,\n#   Distance_Unit &lt;chr&gt;, Road_Grade &lt;chr&gt;, NonTraffic &lt;chr&gt;, Road_Name &lt;chr&gt;,\n#   Cross_Street_Type &lt;chr&gt;, Cross_Street_Name &lt;chr&gt;, At_Fault &lt;chr&gt;,\n#   Collision_Type &lt;chr&gt;, Weather &lt;chr&gt;, Surface_Condition &lt;chr&gt;, Light &lt;chr&gt;,\n#   Traffic_Control &lt;chr&gt;, Driver_Substance_Abuse &lt;chr&gt;, …\n\n\n\n\nCode\nggplot(dt_temporal_month) +\n  geom_boxplot(mapping=aes(x=Month, y=total_accidents))\n\n\n\n\n\nCode\nlibrary(ggridges)\n\n\nWarning: package 'ggridges' was built under R version 4.3.1\n\n\nCode\n### Distribution of total number of accidents by month\nggplot(dt_temporal_month) +\n  geom_boxplot(mapping = aes(x = total_accidents, y = Month)) +\n  geom_density_ridges(mapping = aes(x = total_accidents, y = Month), alpha = 0.5) +\n  theme_minimal() +\n  labs(title = \"Distribution of total number of accidents by month\")\n\n\nPicking joint bandwidth of 12.3\n\n\n\n\n\nCode\n#Distribution of total number of accidents by Day of week\nggplot(dt_temporal_month) +\n  geom_boxplot(mapping = aes(x = total_accidents, y = Week_day)) +\n  geom_density_ridges(mapping = aes(x = total_accidents, y = Week_day), alpha = 0.5) +\n  theme_minimal() +\n  labs(title = \"Distribution of total number of accidents by weekday\")\n\n\nPicking joint bandwidth of 9.83\n\n\n\n\n\n\n\nCode\nlibrary(ggridges)\nlibrary(patchwork)\n\n\nWarning: package 'patchwork' was built under R version 4.3.2\n\n\nCode\ndt_temporal_1 &lt;- dt_temporal\n# Convert the Month column to display the abbreviation version\n# Create a list of month abbreviations\nmonth_abbreviations &lt;- c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\")\nweekday_labels &lt;- c(\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\")\n\n# Convert the Week_day column to display the abbreviation version\ndt_temporal_1$Week_day &lt;- ifelse(dt_temporal_1$Week_day == \"Sunday\", \"Sun\",\n                             ifelse(dt_temporal_1$Week_day == \"Monday\", \"Mon\",\n                             ifelse(dt_temporal_1$Week_day == \"Tuesday\", \"Tue\",\n                             ifelse(dt_temporal_1$Week_day == \"Wednesday\", \"Wed\",\n                             ifelse(dt_temporal_1$Week_day == \"Thursday\", \"Thu\",\n                             ifelse(dt_temporal_1$Week_day == \"Friday\", \"Fri\",\n                             ifelse(dt_temporal_1$Week_day == \"Saturday\", \"Sat\", dt_temporal_1$Week_day)))))))\n\ndt_temporal_1$Week_day &lt;- factor(dt_temporal_1$Week_day , levels = weekday_labels)\n\n# Convert the Month column to display the abbreviation version\ndt_temporal_1$Month &lt;- ifelse(dt_temporal_1$Month == \"January\", \"Jan\",\n                          ifelse(dt_temporal_1$Month == \"February\", \"Feb\",\n                          ifelse(dt_temporal_1$Month == \"March\", \"Mar\",\n                          ifelse(dt_temporal_1$Month == \"April\", \"Apr\",\n                          ifelse(dt_temporal_1$Month == \"May\", \"May\",\n                          ifelse(dt_temporal_1$Month == \"June\", \"Jun\",\n                          ifelse(dt_temporal_1$Month == \"July\", \"Jul\",\n                          ifelse(dt_temporal_1$Month == \"August\", \"Aug\",\n                          ifelse(dt_temporal_1$Month == \"September\", \"Sep\",\n                          ifelse(dt_temporal_1$Month == \"October\", \"Oct\",\n                          ifelse(dt_temporal_1$Month == \"November\", \"Nov\",\n                          ifelse(dt_temporal_1$Month == \"December\", \"Dec\", dt_temporal_1$Month))))))))))))\n\ndt_temporal_1$Month &lt;- factor(dt_temporal_1$Month, levels = month_abbreviations)\n\ndt_temporal_month &lt;- dt_temporal_1 |&gt; group_by(Month, first_day_of_month, Week_day) |&gt; summarise(total_accidents = n())\n\n\n`summarise()` has grouped output by 'Month', 'first_day_of_month'. You can\noverride using the `.groups` argument.\n\n\nCode\ndt_temporal_hour &lt;- dt_temporal_1 |&gt; group_by(Month, first_day_of_month, Crash_Hour) |&gt; summarise(total_accidents = n())\n\n\n`summarise()` has grouped output by 'Month', 'first_day_of_month'. You can\noverride using the `.groups` argument.\n\n\nCode\n# Distribution of total number of accidents by month (the total number of accidents is with the total within in Year-Month combination)\nplot_month &lt;- ggplot(dt_temporal_month |&gt; mutate(Month = as.factor(Month))) +\n  geom_boxplot(mapping = aes(x = total_accidents, y = Month)) +\n  geom_density_ridges(mapping = aes(x = total_accidents, y = Month), alpha = 0.5) +\n  theme_minimal() +\n  labs(subtitle = \"By month\")\n\n# Distribution of total number of accidents by Day of week (the total number of accidents is with the total within in Year-Month combination)\nplot_weekday &lt;- ggplot(dt_temporal_month) +\n  geom_boxplot(mapping = aes(x = total_accidents, y = Week_day)) +\n  geom_density_ridges(mapping = aes(x = total_accidents, y = Week_day), alpha = 0.5) +\n  theme_minimal() +\n  labs(subtitle = \"By weekday\")\n\n\n# Distribution of total number of accidents by Hour (the total number of accidents is with the total within in Year-Month combination)\n\nplot_hours &lt;- ggplot(dt_temporal_hour |&gt; mutate(Crash_Hour = as.factor(Crash_Hour))) +\n  geom_boxplot(mapping = aes(x = total_accidents, y = Crash_Hour)) +\n  geom_density_ridges(mapping = aes(x = total_accidents, y = Crash_Hour), alpha = 0.5) +\n  theme_minimal() +\n  labs(subtitle = \"By weekday\")\n\n\n\n# Combine the plots side by side\n# combined_plots &lt;- plot_month + plot_weekday + plot_hours\n\n# Combine the plots side by side with one common title\ncombined_plots &lt;- plot_month + plot_weekday + plot_hours +\n  plot_layout(ncol = 2, heights = c(2, 2)) +\n  plot_annotation(title = \"Distribution of total number of accidents\")\n\n\n# Print the combined plots\nprint(combined_plots)\n\n\nPicking joint bandwidth of 11.2\nPicking joint bandwidth of 8.8\nPicking joint bandwidth of 3.02\n\n\n\n\n\n\nBy combining histograms and density plots, we gain valuable insights into the distribution of total accidents aggregated by months per year, examining variations across different months, weekdays, and day-hours\nNumber of accidents per month: Analyzing the density plots reveals a similar distribution in the total number of accidents across different months. However, delving into boxplots exposes distinct variances; for instance, the interquartile range (IQR) for January is significantly wider than that of February.\nNumber of accidents per weekday: The density plots unveil noticeable differences in the distribution of total accidents between weekends and weekdays, providing insights into the varying patterns throughout the week.\nNumber of accidents per Hour in day: Exploring the density plots illustrates significant disparities in the distribution of total accidents across different times of the day. Notably, there is typically an increase in accidents during the middle of the day, aligning with the expected higher traffic volumes during those hours.\n\n\n\n3.3.1 Time-plot displaying the total number of accidents trend over the years faceted by weekdays\n\n\nCode\n# ggplot(dt_temporal_Year_month, aes(x=first_day_of_month, y=total_accidents)) + \n#   geom_line() + \n#   geom_point() + \n#   facet_grid(Week_day~.)\n\n# Filter data for December\ndecember_data &lt;- dt_temporal_Year_month %&gt;%\n  filter(month(first_day_of_month) == 12)\n\nhighest_points &lt;- dt_temporal_Year_month %&gt;%\n  group_by(Year, Week_day) %&gt;%\n  slice_max(order_by = total_accidents)\n\nggplot(dt_temporal_Year_month, aes(x=first_day_of_month, y=total_accidents)) + \n  geom_line() + \n  stat_smooth(method = \"loess\", span=0.63, col = \"blue\", size = 1, se = FALSE) +  # Add a moving average line\n  geom_point(data = highest_points, col = \"black\", size = 1.4) +  # Add points only for Jan\n  facet_grid(~Week_day) +\n  labs(title = \"line plot of total accidents faceted by weekday\",\n       subtitle = \"The black dots present for each year the month with \\nthe highest number of accidents\")\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\nIn the faceted line graph, a consistent trend is apparent in the number of accidents per weekday, suggesting a similar pattern across the week. However, the magnitude of accidents varies, with fewer incidents occurring on weekends, which aligns with expectations. Notably, the middle of the week appears to experience a higher frequency of accidents.\nFurthermore, an examination of the “black dots,” representing each year’s month with the highest number of accidents, provides additional insights. Comparing these dots across different weekdays reveals distinctions, and an intriguing observation emerges when connecting these dots. If we were to draw a line connecting each black dot, a trend similar to the loess blue line trend in the plot becomes evident, indicating a potential overarching pattern in the occurrence of maximum accidents over the years.\n\n\n\n3.3.2 Hit/run\n\n\nCode\ndt_temporal_Year_month_hit_run &lt;- dt_temporal |&gt; group_by(Year, Month, first_day_of_month, Week_day, Hit_Run) |&gt; summarise(total_accidents = n())\n\n\n`summarise()` has grouped output by 'Year', 'Month', 'first_day_of_month',\n'Week_day'. You can override using the `.groups` argument.\n\n\nCode\ndt_temporal_Year_month_hit_run &lt;- dt_temporal |&gt; group_by(Year, Month, first_day_of_month, Week_day, Hit_Run) |&gt; summarise(total_accidents = n())\n\n\n`summarise()` has grouped output by 'Year', 'Month', 'first_day_of_month',\n'Week_day'. You can override using the `.groups` argument.\n\n\nCode\n# ggplot(dt_temporal_Year_month_hit_run, aes(x=first_day_of_month, y=total_accidents)) + \n#   geom_line() + \n#   stat_smooth(method = \"loess\", span=0.63, col = \"blue\", size = 1, se = FALSE) +  # Add a moving average line\n#   facet_grid(~Hit_Run) +\n#   labs(title = \"line plot of total accidents faceted by weekday\",\n#        subtitle = \"The black dots present for each year the month with \\nthe highest number of accidents\")\n\n\ngroup by –&gt; sum up the number of accident with No and with Yes road\n##Is it more likely to Hit and Run in a specific Month / Week day / Hour?\n\n\nCode\nlibrary(patchwork)\n\n# Filter out NA values for Hit_Run\nfiltered_data &lt;- dt_temporal %&gt;%\n  filter(!is.na(Hit_Run))\n\n# Abbreviate the Month and Weekday names\nmonth_labels &lt;- c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\")\nweekday_labels &lt;- c(\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\")\n\n# Create a bar plot for Month\nplot_month &lt;- ggplot(filtered_data) +\n  geom_bar(aes(x = Month, fill = Hit_Run), position = \"fill\") +\n  scale_fill_manual(values = c(\"No\" = \"tomato\", \"Yes\" = \"darkgreen\")) +\n  labs(title = \"Proportion of Hit-Run Accidents\",\n       subtitle = \"Per Month of Year\",\n       x = \"Month\",\n       y = \"Proportion\") +\n  scale_x_discrete(labels = month_labels) +  # Abbreviate Month names\n  theme_minimal() +\n  theme(legend.position = \"none\")  # Remove the legend\n\n# Create a bar plot for Weekday\nplot_weekday &lt;- ggplot(filtered_data) +\n  geom_bar(aes(x = Week_day, fill = Hit_Run), position = \"fill\") +\n  scale_fill_manual(values = c(\"No\" = \"tomato\", \"Yes\" = \"darkgreen\")) +\n  labs(title = \"Proportion of Hit-Run Accidents\",\n       subtitle = \"Per Weekday\",\n       x = \"Weekday\",\n       y = \"Proportion\") +\n  scale_x_discrete(labels = weekday_labels) +  # Abbreviate Weekday names\n  theme_minimal()\n\n# Arrange the two plots side by side\ncombined_plot &lt;- plot_month + plot_weekday\n\n# Print the combined plot\nprint(combined_plot)\n\n\n\n\n\nCode\n### Plot Hit-Run by hours\n### divide the crash hour into groups\ndt_temporal$Crash_Hour_Group &lt;- cut(dt_temporal$Crash_Hour,\n  breaks = c(0, 4, 8, 12, 16, 20, 24),\n  labels = c(\"0-4\", \"4-8\", \"8-12\", \"12-16\", \"16-20\", \"20-24\"),\n  include.lowest = TRUE\n)\n\n\nggplot(dt_temporal %&gt;%\n         filter(!is.na(Hit_Run))) +\n  geom_bar(aes(x = Crash_Hour_Group, fill = Hit_Run), position = \"fill\") +\n  labs(title = \"Proportion of Hit and Run Incidents by Crash Hour\",\n       x = \"Crash Hour\",\n       y = \"Proportion\") +\n  scale_fill_manual(values = c(\"No\" = \"tomato\", \"Yes\" = \"darkgreen\")) +  # Customize colors if needed\n  theme_minimal()\n\n\n\n\n\n\nThere doesn’t appear to be a correlation between the month and Hit-Run incidents; in other words, there isn’t a particular month with a higher likelihood of a Hit-Run accident.\nHowever, we observe a higher proportion of Hit-Run incidents during weekends (Saturday and Sunday) compared to the proportions on other weekdays.\nConcerning the Hit-Run proportion per hour—there is an observed escalation in the proportion of Hit-Run accidents during late hours. Furthermore, there seems to be a consistent “linear trend” in Hit-Run incidents as the day unfolds.\n\n\n\n3.3.3 First_Harmful_Event\n\n\nCode\n#count(dt_temporal, First_Harmful_Event) |&gt; arrange(desc(n))\n\n### taking only the 7 top categories in  First_Harmful_Event\ndf_for_harmful_event &lt;- dt_temporal %&gt;%\n  filter(!is.na(First_Harmful_Event)) %&gt;%  # Remove NA values\n  mutate(\n    First_Harmful_Event = tolower(First_Harmful_Event),\n    First_Harmful_Event = factor(First_Harmful_Event) %&gt;% fct_lump(n = 7, other_level = \"Other\"))\n\n###Mosaic plot 1:\nmosaicplot(table(factor(df_for_harmful_event$First_Harmful_Event), df_for_harmful_event$Hit_Run), main= \"Mosaic plot for Hit Run vs First Harmful Event\",\n           color = c('tomato', 'darkgreen'), \n           las = 2  # Rotate labels by 90 degrees\n)\n\n\n\n\n\nCode\ncount(df_for_harmful_event, Hit_Run, First_Harmful_Event)\n\n\n# A tibble: 18 × 3\n   Hit_Run First_Harmful_Event     n\n   &lt;chr&gt;   &lt;fct&gt;               &lt;int&gt;\n 1 No      animal                815\n 2 No      bicycle               724\n 3 No      fixed object         9489\n 4 No      off road              936\n 5 No      other vehicle       50411\n 6 No      parked vehicle       4541\n 7 No      pedestrian           2789\n 8 No      Other                1609\n 9 Yes     animal                 14\n10 Yes     bicycle               116\n11 Yes     fixed object         1074\n12 Yes     off road               73\n13 Yes     other vehicle        9565\n14 Yes     parked vehicle       3470\n15 Yes     pedestrian            597\n16 Yes     Other                 174\n17 &lt;NA&gt;    bicycle                 1\n18 &lt;NA&gt;    pedestrian              1\n\n\nCode\n#+\n # scale_fill_manual(values = c(\"No\" = \"tomato\", \"Yes\" = \"darkgreen\")) +\n\n\n\nWe can see that the first harmful event has a great connection / correlation to the Hit-Run variable –&gt; there are great variations between the proportion of Hit-Run vs. Not Hit-Run accidents given the different First_Harmful_Event categories.\nNote that for “Parked-Vehicle” the proportion of Hit-Run is 0.45 which is more than twice as big as the overall Hit-Run proportion (0.18):\n\n\n\nCode\ndt_temporal |&gt; count(Hit_Run) |&gt; mutate(\"prop\" = n/nrow(dt_temporal))\n\n\n# A tibble: 3 × 3\n  Hit_Run     n      prop\n  &lt;chr&gt;   &lt;int&gt;     &lt;dbl&gt;\n1 No      71764 0.826    \n2 Yes     15162 0.174    \n3 &lt;NA&gt;        2 0.0000230\n\n\nCode\na &lt;- dt_temporal |&gt; filter(grepl(c(\"Parked\"), First_Harmful_Event, ignore.case = T)) |&gt; count(Hit_Run, First_Harmful_Event) \na|&gt; mutate(\"prop\" = n/sum(a$n)) \n\n\n# A tibble: 2 × 4\n  Hit_Run First_Harmful_Event     n  prop\n  &lt;chr&gt;   &lt;chr&gt;               &lt;int&gt; &lt;dbl&gt;\n1 No      PARKED VEHICLE       4541 0.567\n2 Yes     PARKED VEHICLE       3470 0.433"
  },
  {
    "objectID": "results.html#weather",
    "href": "results.html#weather",
    "title": "3  Results",
    "section": "3.4 Weather",
    "text": "3.4 Weather\n\n\nCode\ndf_mosaic_by_weather &lt;- dt_temporal |&gt; group_by(Weather, Hit_Run) |&gt; summarise(Freq = n())\n\n\n`summarise()` has grouped output by 'Weather'. You can override using the\n`.groups` argument.\n\n\nCode\n###Mosaic plot 1:\nmosaicplot(table(dt_temporal$Weather, dt_temporal$Hit_Run), main= \"Mosaic plot for Hit Run vs First Harmful Event\",\n           color = c('tomato', 'darkgreen'), \n           las = 2  # Rotate labels by 90 degrees\n)\n\n\n\n\n\nCode\nvcd:: mosaic(Hit_Run ~ Weather,\n data = df_mosaic_by_weather,\n direction = c(\"v\", \"h\"), \n highlighting_fill=c('tomato','darkgreen'))"
  },
  {
    "objectID": "results.html#things-we-found-from-graphs-we-created",
    "href": "results.html#things-we-found-from-graphs-we-created",
    "title": "3  Results",
    "section": "3.5 Things we found from graphs we created”",
    "text": "3.5 Things we found from graphs we created”\n\nWe checked and there doesn’t seem to be a correlation between the Weather and the Hit_Run\n\n\n\nCode\ndt_temporal_week\n\n\n# A tibble: 464 × 16\n# Groups:   Crash_week [464]\n   Crash_Date_Time     Weather   Hit_Run First_Harmful_Event At_Fault Crash_Date\n   &lt;dttm&gt;              &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;               &lt;chr&gt;    &lt;date&gt;    \n 1 2015-01-01 19:52:00 CLEAR     Yes     PARKED VEHICLE      DRIVER   2015-01-01\n 2 2015-01-04 07:19:00 FOGGY     Yes     OTHER VEHICLE       DRIVER   2015-01-04\n 3 2015-01-11 14:57:00 CLEAR     No      OTHER VEHICLE       DRIVER   2015-01-11\n 4 2015-01-18 19:24:00 RAINING   No      OFF ROAD            DRIVER   2015-01-18\n 5 2015-01-25 03:15:00 &lt;NA&gt;      No      PARKED VEHICLE      DRIVER   2015-01-25\n 6 2015-02-01 11:28:00 CLEAR     No      OTHER VEHICLE       DRIVER   2015-02-01\n 7 2015-02-08 14:20:00 CLEAR     No      OTHER VEHICLE       DRIVER   2015-02-08\n 8 2015-02-15 02:45:00 SEVERE W… Yes     OTHER VEHICLE       DRIVER   2015-02-15\n 9 2015-02-22 19:43:00 CLEAR     No      OTHER VEHICLE       DRIVER   2015-02-22\n10 2015-03-01 12:15:00 WINTRY M… No      OTHER VEHICLE       DRIVER   2015-03-01\n# ℹ 454 more rows\n# ℹ 10 more variables: Crash_Time &lt;time&gt;, Week_day &lt;fct&gt;, Month &lt;fct&gt;,\n#   Year &lt;dbl&gt;, first_day_of_month &lt;date&gt;, Crash_Hour &lt;int&gt;, Crash_week &lt;date&gt;,\n#   Count_week &lt;int&gt;, Crash_month &lt;dbl&gt;, is_holiday &lt;chr&gt;\n\n\nCode\nts_data &lt;- ts(data = dt_temporal_week$Crash_week, start = c(2015,1,3), end = c(2023,11,13), frequency = 51)\n\n#dt_temporal_week$Crash_Date[nrow(dt_temporal_week)]\n\n\n# \n# ts_data&lt;- ts(df_temporal_week$Crash_week)\n# plot(decompose())\n\n\nBox plot x axis - day of week the box itself will use the number of accidents"
  },
  {
    "objectID": "results.html#ethan-part",
    "href": "results.html#ethan-part",
    "title": "3  Results",
    "section": "3.7 Ethan Part",
    "text": "3.7 Ethan Part\n\n\nCode\ndt_lane &lt;- data_crash[,c(\"Hit_Run\",\"Route_Type\",\"Number_of_Lanes\",\"NonTraffic\",\"Road_Grade\",\"At_Fault\",\"Cross_Street_Type\",\"Collision_Type\",\"Traffic_Control\",\"Driver_Substance_Abuse\",\"Road_Alignment\",\"Junction\",\"Road_Condition\",\"Road_Division\",\"First_Harmful_Event\",\"Light\",\"Surface_Condition\")]\n\n\n\n\nCode\n# Assuming 'data' is your data frame\nunique_values &lt;- lapply(dt_lane, unique)\n\n# Print unique values for each column\nfor (col_name in names(unique_values)) {\n  cat(\"Column:\", col_name, \"\\n\")\n  print(unique_values[[col_name]])\n  cat(\"\\n\")\n}\n\n\nColumn: Hit_Run \n[1] \"No\"  \"Yes\" NA   \n\nColumn: Route_Type \n [1] NA                     \"County\"               \"Maryland (State)\"    \n [4] \"Municipality\"         \"Other Public Roadway\" \"US (State)\"          \n [7] \"Interstate (State)\"   \"Unknown\"              \"Government\"          \n[10] \"Ramp\"                 \"Service Road\"        \n\nColumn: Number_of_Lanes \n [1]  0  2  1  6  3  5  4  7  8 12 11 10 13 99  9 19\n\nColumn: NonTraffic \n[1] \"Yes\" \"No\" \n\nColumn: Road_Grade \n[1] NA               \"LEVEL\"          \"HILL UPHILL\"    \"GRADE DOWNHILL\"\n[5] \"HILL CREST\"     \"OTHER\"          \"UNKNOWN\"        \"DIP SAG\"       \n[9] \"ON BRIDGE\"     \n\nColumn: At_Fault \n[1] \"DRIVER\"      \"UNKNOWN\"     \"NONMOTORIST\" \"BOTH\"       \n\nColumn: Cross_Street_Type \n [1] NA                     \"County\"               \"Ramp\"                \n [4] \"Municipality\"         \"Maryland (State)\"     \"Other Public Roadway\"\n [7] \"Interstate (State)\"   \"Unknown\"              \"Government\"          \n[10] \"US (State)\"           \"Service Road\"        \n\nColumn: Collision_Type \n [1] \"SINGLE VEHICLE\"               \"STRAIGHT MOVEMENT ANGLE\"     \n [3] \"OTHER\"                        \"SAME DIR REAR END\"           \n [5] \"SAME DIRECTION SIDESWIPE\"     \"HEAD ON LEFT TURN\"           \n [7] \"OPPOSITE DIRECTION SIDESWIPE\" \"SAME DIRECTION RIGHT TURN\"   \n [9] \"ANGLE MEETS LEFT TURN\"        \"SAME DIR REND LEFT TURN\"     \n[11] \"HEAD ON\"                      \"SAME DIRECTION LEFT TURN\"    \n[13] \"ANGLE MEETS LEFT HEAD ON\"     NA                            \n[15] \"SAME DIR BOTH LEFT TURN\"      \"ANGLE MEETS RIGHT TURN\"      \n[17] \"UNKNOWN\"                      \"OPPOSITE DIR BOTH LEFT TURN\" \n[19] \"SAME DIR REND RIGHT TURN\"    \n\nColumn: Traffic_Control \n [1] \"NO CONTROLS\"             \"TRAFFIC SIGNAL\"         \n [3] \"STOP SIGN\"               NA                       \n [5] \"FLASHING TRAFFIC SIGNAL\" \"OTHER\"                  \n [7] \"UNKNOWN\"                 \"PERSON\"                 \n [9] \"WARNING SIGN\"            \"YIELD SIGN\"             \n[11] \"SCHOOL ZONE SIGN DEVICE\" \"RAILWAY CROSSING DEVICE\"\n\nColumn: Driver_Substance_Abuse \n [1] \"NONE DETECTED\"                                 \n [2] NA                                              \n [3] \"UNKNOWN\"                                       \n [4] \"ALCOHOL CONTRIBUTED, NONE DETECTED\"            \n [5] \"NONE DETECTED, UNKNOWN\"                        \n [6] \"N/A, NONE DETECTED\"                            \n [7] \"ALCOHOL PRESENT, NONE DETECTED\"                \n [8] \"ALCOHOL PRESENT\"                               \n [9] \"COMBINED SUBSTANCE PRESENT\"                    \n[10] \"N/A, UNKNOWN\"                                  \n[11] \"ILLEGAL DRUG CONTRIBUTED\"                      \n[12] \"ALCOHOL PRESENT, N/A\"                          \n[13] \"ILLEGAL DRUG PRESENT\"                          \n[14] \"ALCOHOL CONTRIBUTED\"                           \n[15] \"N/A, NONE DETECTED, UNKNOWN\"                   \n[16] \"COMBINED SUBSTANCE PRESENT, NONE DETECTED\"     \n[17] \"ILLEGAL DRUG PRESENT, NONE DETECTED\"           \n[18] \"ALCOHOL CONTRIBUTED, N/A\"                      \n[19] \"MEDICATION CONTRIBUTED\"                        \n[20] \"MEDICATION PRESENT, NONE DETECTED\"             \n[21] \"ILLEGAL DRUG CONTRIBUTED, NONE DETECTED\"       \n[22] \"MEDICATION PRESENT\"                            \n[23] \"COMBINATION CONTRIBUTED\"                       \n[24] \"COMBINATION CONTRIBUTED, NONE DETECTED\"        \n[25] \"COMBINED SUBSTANCE PRESENT, N/A\"               \n[26] \"ILLEGAL DRUG PRESENT, N/A\"                     \n[27] \"MEDICATION CONTRIBUTED, NONE DETECTED\"         \n[28] \"MEDICATION CONTRIBUTED, NONE DETECTED, UNKNOWN\"\n[29] \"NONE DETECTED, OTHER\"                          \n[30] \"ALCOHOL PRESENT, N/A, NONE DETECTED\"           \n[31] \"COMBINATION CONTRIBUTED, N/A\"                  \n[32] \"OTHER\"                                         \n[33] \"ILLEGAL DRUG CONTRIBUTED, N/A\"                 \n[34] \"ALCOHOL PRESENT, UNKNOWN\"                      \n[35] \"MEDICATION PRESENT, N/A\"                       \n[36] \"ALCOHOL PRESENT, NONE DETECTED, UNKNOWN\"       \n[37] \"ALCOHOL CONTRIBUTED, UNKNOWN\"                  \n[38] \"ALCOHOL CONTRIBUTED, ALCOHOL PRESENT\"          \n[39] \"N/A, OTHER\"                                    \n[40] \"ALCOHOL PRESENT, N/A, UNKNOWN\"                 \n[41] \"MEDICATION CONTRIBUTED, N/A\"                   \n[42] \"ILLEGAL DRUG PRESENT, N/A, NONE DETECTED\"      \n[43] \"COMBINED SUBSTANCE PRESENT, UNKNOWN\"           \n[44] \"ALCOHOL CONTRIBUTED, N/A, NONE DETECTED\"       \n[45] \"MEDICATION PRESENT, NONE DETECTED, UNKNOWN\"    \n[46] \"COMBINED SUBSTANCE PRESENT, N/A, NONE DETECTED\"\n[47] \"ILLEGAL DRUG PRESENT, UNKNOWN\"                 \n[48] \"MEDICATION PRESENT, N/A, UNKNOWN\"              \n[49] \"ALCOHOL CONTRIBUTED, NONE DETECTED, UNKNOWN\"   \n[50] \"ALCOHOL PRESENT, ILLEGAL DRUG PRESENT\"         \n\nColumn: Road_Alignment \n[1] NA            \"STRAIGHT\"    \"CURVE RIGHT\" \"CURVE LEFT\"  \"OTHER\"      \n[6] \"UNKNOWN\"    \n\nColumn: Junction \n [1] NA                       \"INTERSECTION\"           \"NON INTERSECTION\"      \n [4] \"OTHER\"                  \"INTERSECTION RELATED\"   \"INTERCHANGE RELATED\"   \n [7] \"CROSSOVER RELATED\"      \"COMMERCIAL DRIVEWAY\"    \"OTHER DRIVEWAY\"        \n[10] \"RESIDENTIAL DRIVEWAY\"   \"ALLEY\"                  \"UNKNOWN\"               \n[13] \"RAILWAY GRADE CROSSING\"\n\nColumn: Road_Condition \n [1] NA                         \"NO DEFECTS\"              \n [3] \"LOOSE SURFACE MATERIAL\"   \"UNKNOWN\"                 \n [5] \"HOLES RUTS ETC\"           \"OBSTRUCTION NOT SIGNALED\"\n [7] \"OBSTRUCTION NOT LIGHTED\"  \"FOREIGN MATERIAL\"        \n [9] \"SHOULDER DEFECT\"          \"VIEW OBSTRUCTED\"         \n[11] \"OTHER\"                   \n\nColumn: Road_Division \n[1] NA                                                \n[2] \"TWO-WAY, DIVIDED, UNPROTECTED PAINTED MIN 4 FEET\"\n[3] \"TWO-WAY, NOT DIVIDED\"                            \n[4] \"TWO-WAY, DIVIDED, POSITIVE MEDIAN BARRIER\"       \n[5] \"OTHER\"                                           \n[6] \"ONE-WAY TRAFFICWAY\"                              \n[7] \"TWO-WAY, NOT DIVIDED WITH A CONTINUOUS LEFT TURN\"\n[8] \"UNKNOWN\"                                         \n\nColumn: First_Harmful_Event \n [1] \"FIXED OBJECT\"                   \"OTHER VEHICLE\"                 \n [3] \"PARKED VEHICLE\"                 \"OFF ROAD\"                      \n [5] \"PEDESTRIAN\"                     \"DOWNHILL RUNAWAY\"              \n [7] NA                               \"OTHER NON COLLISION\"           \n [9] \"OTHER OBJECT\"                   \"FELL JUMPED FROM MOTOR VEHICLE\"\n[11] \"ANIMAL\"                         \"BICYCLE\"                       \n[13] \"UNKNOWN\"                        \"OTHER\"                         \n[15] \"OVERTURN\"                       \"JACKKNIFE\"                     \n[17] \"THROWN OR FALLING OBJECT\"       \"BACKING\"                       \n[19] \"OTHER CONVEYANCE\"               \"OTHER PEDALCYCLE\"              \n[21] \"U-TURN\"                         \"RAILWAY TRAIN\"                 \n[23] \"SPILLED CARGO\"                  \"IMMERSION\"                     \n[25] \"UNITS SEPARATED\"                \"EXPLOSION OR FIRE\"             \n\nColumn: Light \n[1] \"DARK NO LIGHTS\"           \"DAYLIGHT\"                \n[3] \"DARK LIGHTS ON\"           \"DARK -- UNKNOWN LIGHTING\"\n[5] \"DUSK\"                     NA                        \n[7] \"OTHER\"                    \"DAWN\"                    \n[9] \"UNKNOWN\"                 \n\nColumn: Surface_Condition \n [1] NA                       \"DRY\"                    \"WET\"                   \n [4] \"UNKNOWN\"                \"MUD, DIRT, GRAVEL\"      \"WATER(STANDING/MOVING)\"\n [7] \"SNOW\"                   \"ICE\"                    \"OIL\"                   \n[10] \"OTHER\"                  \"SLUSH\"                  \"SAND\"                  \n\n\n\n\nCode\ncount(data_crash, Traffic_Control)\n\n\n# A tibble: 12 × 2\n   Traffic_Control             n\n   &lt;chr&gt;                   &lt;int&gt;\n 1 FLASHING TRAFFIC SIGNAL  1119\n 2 NO CONTROLS             40760\n 3 OTHER                    1125\n 4 PERSON                    162\n 5 RAILWAY CROSSING DEVICE    26\n 6 SCHOOL ZONE SIGN DEVICE    14\n 7 STOP SIGN                6525\n 8 TRAFFIC SIGNAL          28444\n 9 UNKNOWN                   231\n10 WARNING SIGN              114\n11 YIELD SIGN                899\n12 &lt;NA&gt;                    16165\n\n\n\n\nCode\ndt_intersection &lt;- data_crash %&gt;%\n   mutate(Traffic_Control = recode(Traffic_Control,\n        \"FLASHING TRAFFIC SIGNAL\" = \"Traffic Light\",\n        \"TRAFFIC SIGNAL\" = \"Traffic Light\",\n        \"NO CONTROLS\" = 'No Controls',\n        \"RAILWAY CROSSING DEVICE    \" = 'Warning Sign',\n        \"WARNING SIGN\" = 'Warning Sign',\n        \"SCHOOL ZONE SIGN DEVICE\" = 'Warning Sign',\n        \"YIELD SIGN\" = 'Warning Sign',\n        \"STOP SIGN\" = 'Stop Sign',\n        .default  = 'Other')) %&gt;%\n  filter(!is.na(Traffic_Control))\n\n#count(dt_intersection, Traffic_Control)\n  \nggplot(dt_intersection, aes(x=Traffic_Control))+\n  geom_bar()\n\n\n\n\n\n\n\nCode\nfiltered_data_crash &lt;- data_crash[!is.na(data_crash$Cross_Street_Type),]\n\n\nb &lt;- apply(filtered_data_crash, 2, function(c) sum(is.na(c)))\ntibble_nas &lt;- tibble(column_name = names(b), number_of_NA = b)\ntibble_nas_filtered_data_crash &lt;- tibble_nas\n\nb &lt;- apply(data_crash, 2, function(c) sum(is.na(c)))\ntibble_nas_data_crash &lt;- tibble(column_name = names(b), number_of_NA = b)\n\n#Compare the 2 lists, the one with all the column with less that 1000 NAs and the lists with the same conditions but after removing all the NAs row in the column \"Cross-Street Type\"\na &lt;- tibble_nas_data_crash |&gt; filter(number_of_NA&lt;1000)\nb &lt;- tibble_nas_filtered_data_crash |&gt; filter(number_of_NA&lt;1000)\n\n# Get the name of the column which are not in common in the 2 previous list\ndifference_both_ways &lt;- union(setdiff(a$column_name, b$column_name), setdiff(b$column_name, a$column_name))\n\n\n\n\nCode\ndt_sameNa &lt;- data_crash %&gt;%\n  select(difference_both_ways) %&gt;%\n  filter(rowSums(is.na(.)) &lt; ncol(.))\n\n\nWarning: Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %&gt;% select(difference_both_ways)\n\n  # Now:\n  data %&gt;% select(all_of(difference_both_ways))\n\nSee &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\n\n\nCode\ndt_lane &lt;- data_crash[,c(\"Road_Division\", \"Junction\", \"Road_Alignment\" ,\"Traffic_Control\",\"Road_Name\",\"Number_of_Lanes\")]\n\n\ndt_responsible &lt;- data_crash[,c(\"Hit_Run\",\"NonTraffic\",\"At_Fault\",\"Driver_Substance_Abuse\")]\n\n\n\n\nCode\n#Change the column Road_type to get rid of the Na and the values unknown\ndt_lane &lt;- dt_lane %&gt;%\n  mutate(Road_Division = recode(Road_Division,\n        \"TWO-WAY, NOT DIVIDED WITH A CONTINUOUS LEFT TURN\" = \"2-way, not divided\",\n        \"TWO-WAY, NOT DIVIDED\" = \"2-way, not divided\",\n        \"TWO-WAY, DIVIDED, POSITIVE MEDIAN BARRIER\" = '2-way, divided',\n        \"TWO-WAY, DIVIDED, UNPROTECTED PAINTED MIN 4 FEET\" = '2-way, divided',\n        \"ONE-WAY TRAFFICWAY\" = '1-way',\n        \"OTHER\" = 'Other')) %&gt;%\n  filter(Road_Division != 'UNKNOWN') %&gt;%\n  filter(Road_Division != 'Other') %&gt;%\n  na.omit()\n\n#Change the column Number of Lanes to remove the lanes with more than ... lanes\ndt_lane &lt;- dt_lane %&gt;%\n  filter(Number_of_Lanes &lt; 7) %&gt;%\n  filter(Number_of_Lanes != 0)\n  \n\n\ndt_lane$Road_Division &lt;- factor(dt_lane$Road_Division, levels = c(\"1-way\", \"2-way, not divided\", \"2-way, divided\", 'Other'))\n\nggplot(dt_lane, aes(x=Road_Division))+\n  geom_bar() +\n  facet_wrap(~Number_of_Lanes)+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\nCode\nggplot(dt_lane, aes(y=Road_Division))+\n  geom_bar() +\n  facet_grid(Number_of_Lanes~.)+\n  #theme(axis.text.x = element_text(angle = 45, hjust = 1))+\n  labs(title ='Facet by number of Lanes' )\n\n\n\n\n\nComment : One can see that most of the accidents that happends on 3 lanes road are 2-way and divided (most likely highway).\n\n\nCode\nNbroads = n_distinct(data_crash$Road_Name)\ncount(dt_lane, Number_of_Lanes)\n\n\n# A tibble: 6 × 2\n  Number_of_Lanes     n\n            &lt;dbl&gt; &lt;int&gt;\n1               1 13058\n2               2 20821\n3               3 20418\n4               4  4669\n5               5  1015\n6               6   964\n\n\nCode\nroad_counts &lt;- dt_lane %&gt;%\n  group_by(Road_Division) %&gt;%\n  summarise(Unique_Roads = n_distinct(Road_Name)) %&gt;%\n  mutate(Proportion = 100 * Unique_Roads / sum(Unique_Roads))\n\n\nprint(road_counts)\n\n\n# A tibble: 3 × 3\n  Road_Division      Unique_Roads Proportion\n  &lt;fct&gt;                     &lt;int&gt;      &lt;dbl&gt;\n1 1-way                       397       9.81\n2 2-way, not divided         2572      63.6 \n3 2-way, divided             1078      26.6 \n\n\n\n\nCode\ndt_responsible &lt;- dt_responsible %&gt;%\n  mutate(Driver_Substance_Abuse = str_extract(Driver_Substance_Abuse, \"^[^,]+\")) %&gt;%\n  mutate(Driver_Substance_Abuse = recode(Driver_Substance_Abuse,\n    \"ALCOHOL CONTRIBUTED\" =\"alcohol\",\n    \"ALCOHOL PRESENT\" = \"alcohol\",\n    \"COMBINATION CONTRIBUTED\" = \"combined substance\",\n    \"COMBINED SUBSTANCE PRESENT\" = \"combined substance\",\n    \"ILLEGAL DRUG CONTRIBUTED\" = \"illegal drug\",\n    \"ILLEGAL DRUG PRESENT\" = \"illegal drug\",\n    \"MEDICATION CONTRIBUTED\" = \"under medication\",\n    \"MEDICATION PRESENT\" = \"under medication\",\n    \"UNKNOWN\" = 'unknown',\n    \"OTHER\" = 'unknown',\n    \"NONE DETECTED\" = 'none detected'\n  )) %&gt;%\n  filter(Driver_Substance_Abuse != \"N/A\")\n\ncount(dt_responsible,Driver_Substance_Abuse)\n\n\n# A tibble: 6 × 2\n  Driver_Substance_Abuse     n\n  &lt;chr&gt;                  &lt;int&gt;\n1 alcohol                 5393\n2 combined substance       137\n3 illegal drug             355\n4 none detected          64954\n5 under medication         178\n6 unknown                 5043\n\n\nCode\n#redav::plot_missing(dt_responsible) # We see that more than 80% of the rows does not have Na so I will drop all the Na\n\ndt_responsible &lt;- dt_responsible %&gt;%\n  na.omit() %&gt;%\n  filter(Driver_Substance_Abuse != 'none detected') # %&gt;% # remove the none detected because they are too much\n  # filter(Driver_Substance_Abuse != 'alcohol') %&gt;%\n  # filter(Driver_Substance_Abuse != 'unknown')\n\nggplot(dt_responsible, aes(x=Driver_Substance_Abuse))+\n  geom_bar()\n\n\n\n\n\n\n\nCode\nlibrary(gridExtra)\n\n\nWarning: package 'gridExtra' was built under R version 4.3.1\n\n\n\nAttaching package: 'gridExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\n\nCode\ncount(dt_responsible, Driver_Substance_Abuse)\n\n\n# A tibble: 5 × 2\n  Driver_Substance_Abuse     n\n  &lt;chr&gt;                  &lt;int&gt;\n1 alcohol                 5393\n2 combined substance       137\n3 illegal drug             355\n4 under medication         178\n5 unknown                 5043\n\n\nCode\ndt_responsible &lt;- dt_responsible %&gt;%\n  mutate(\n    Driver_Substance_Abuse_A = if_else(Driver_Substance_Abuse %in% c('alcohol', 'unknown'), Driver_Substance_Abuse, NA_character_),\n    Driver_Substance_Abuse_B = if_else(!Driver_Substance_Abuse %in% c('alcohol', 'unknown'), Driver_Substance_Abuse, NA_character_)\n  )\n\n\n\nmp1 &lt;- vcd:: mosaic(Hit_Run ~  Driver_Substance_Abuse_A + NonTraffic,\n data = dt_responsible,\n direction = c(\"v\", \"v\",\"h\" ),\n axes_labels = c('Driver Substance Abuse', 'Traffic'))\n\n\n\n\n\nCode\nmp2 &lt;- vcd:: mosaic(Hit_Run ~  Driver_Substance_Abuse_B + NonTraffic,\n data = dt_responsible,\n direction = c(\"v\", \"v\",\"h\" ),\n axes_labels = c('Driver Substance Abuse', 'Traffic'))\n\n\n\n\n\nThere is more Hit and Run instance when there is no traffic (yes instance for the column NonTraffic) most likely due to the fact that it is easier to go away without traffic on the road.\nComment : One can see that crash accidents occur more during the commute time escpecially the way back home between 15h to 17h."
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "3  Results",
    "section": "",
    "text": "4 D3 - ???"
  },
  {
    "objectID": "results.html#speaking-about-roads-where-are-we",
    "href": "results.html#speaking-about-roads-where-are-we",
    "title": "3  Results",
    "section": "7.1 Speaking about Roads, where are we ?",
    "text": "7.1 Speaking about Roads, where are we ?\n\n\nCode\ndt_lane2 &lt;- dt_lane %&gt;%\n  group_by(Road_Name) %&gt;%\n  mutate(Frequency_road = n()) %&gt;%\n  ungroup() %&gt;%\n  #filter(Frequency &gt;= n_threshold) %&gt;%\n  distinct(Road_Name, .keep_all = TRUE)\n\ntop_10_roads &lt;- dt_lane2 %&gt;%\n  arrange(desc(Frequency_road)) %&gt;%  # Arrange by Frequency in descending order\n  slice_head(n = 10) %&gt;%       # Select the top 10 rows\n  select(Road_Name,Frequency_road) %&gt;%\n  as.list()\n\ntop10 &lt;- top_10_roads$Road_Name\ntop10\n\n\n [1] \"GEORGIA AVE\"       \"NEW HAMPSHIRE AVE\" \"FREDERICK RD\"     \n [4] \"ROCKVILLE PIKE\"    \"CONNECTICUT AVE\"   \"VEIRS MILL RD\"    \n [7] \"RANDOLPH RD\"       \"COLUMBIA PIKE\"     \"SHADY GROVE RD\"   \n[10] \"COLESVILLE RD\"    \n\n\n\nTime-plot displaying the total number of accidents trend over the years faceted by weekdays:\n\nIn the faceted line graph, a consistent trend is apparent in the number of accidents per weekday, suggesting a similar pattern across the week. However, the magnitude of accidents varies, with fewer incidents occurring on weekends, which aligns with expectations. Notably, the middle of the week appears to experience a higher frequency of accidents.\nFurthermore, an examination of the “black dots,” representing each year’s month with the highest number of accidents, provides additional insights. Comparing these dots across different weekdays reveals distinctions, and an intriguing observation emerges when connecting these dots. If we were to draw a line connecting each black dot, a trend similar to the loess blue line trend in the plot becomes evident, indicating a potential overarching pattern in the occurrence of maximum accidents over the years.\n\n\n\n\nCode\n## Filter the highest point in each Year\n# highest_points &lt;- dt_temporal_Year_month %&gt;%\n#   group_by(Year, Week_day) %&gt;%\n#   slice_max(order_by = total_accidents)\n# \n# ggplot(dt_temporal_Year_month, aes(x=first_day_of_month, y=total_accidents)) + \n#   geom_line() + \n#   stat_smooth(method = \"loess\", span=0.63, col = \"blue\", size = 1, se = FALSE) +  # Add a moving average line\n#   geom_point(data = highest_points, col = \"black\", size = 1.4) +  # Add points only for Jan\n#   facet_grid(~Week_day) +\n#   labs(title = \"line plot of total accidents faceted by weekday\",\n#        subtitle = \"The black dots present for each year the month with \\nthe highest number of accidents\")"
  },
  {
    "objectID": "results.html#whos-at-fault",
    "href": "results.html#whos-at-fault",
    "title": "3  Results",
    "section": "3.3 Who’s at Fault ?",
    "text": "3.3 Who’s at Fault ?\nOne thing with Hit and Run is that most of the people are not caught after the accident so we can not have information on them. However some of them\nThere is more Hit and Run instance when there is no traffic (yes instance for the column NonTraffic) most likely due to the fact that it is easier to go away without traffic on the road."
  },
  {
    "objectID": "results.html#preprocess-the-date-time-column",
    "href": "results.html#preprocess-the-date-time-column",
    "title": "3  Results",
    "section": "5.1 Preprocess the Date-Time column",
    "text": "5.1 Preprocess the Date-Time column\nHere we take the date/time column and transform it into the right data type as well as create some distinct date/time columns that will help us investigate and explore the data (time series analysis)\n\n\nCode\ndt_temporal &lt;- dplyr::select(data_crash,c(\"Crash_Date_Time\",\"Weather\", \"Hit_Run\",\n                       \"First_Harmful_Event\", \"At_Fault\"))\n\n#Separate time and Date\ndt_temporal$\"Crash_Date_Time\" &lt;- as.POSIXct(dt_temporal$\"Crash_Date_Time\", format = \"%m/%d/%Y %I:%M:%S %p\", tz = \"America/New_York\")\n\ndt_temporal$Crash_Date &lt;- as.Date(dt_temporal$\"Crash_Date_Time\", tz = \"America/New_York\")\n\ndt_temporal$Crash_Time &lt;- format(dt_temporal$\"Crash_Date_Time\", \"%H:%M:%S\")\ndt_temporal$Crash_Time &lt;- as_hms(dt_temporal$Crash_Time)\ndt_temporal$Crash_Hour &lt;- hour(dt_temporal$Crash_Time) #Crash hour\n\n# Set the local time to english to get the days in English (same for the month)\nSys.setlocale(\"LC_TIME\", \"English\")\n\n\n[1] \"English_United States.1252\"\n\n\nCode\n### add some \"date slicers\" columns\ndt_temporal$Week_day &lt;- weekdays(dt_temporal$Crash_Date)\ndt_temporal$Month &lt;-  months(dt_temporal$Crash_Date)\ndt_temporal$Year &lt;-  year(dt_temporal$Crash_Date)\ndt_temporal$first_day_of_month &lt;- as.Date(format(dt_temporal$Crash_Date, \"%Y-%m-01\"))\n\n\n### Transform some columns to factors --&gt; for visualization purpose\ndt_temporal &lt;- mutate(dt_temporal, Week_day = factor(Week_day,\n                                                     levels = c(\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\")))\n\ndt_temporal &lt;- mutate(dt_temporal, Month = factor(Month,\n                                                     levels = c(\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\"July\", \"August\", \"September\", \"October\", \"November\", \"December\")))\n\n# dt_temporal$Month &lt;- factor(dt_temporal$Month, \n#                           levels = c(\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\"July\", \"August\", \"September\", \"October\", \"November\", \"December\"),)\n\n### arrange the data by date\ndt_temporal &lt;- dt_temporal |&gt; arrange(Crash_Date)\n\ndt_temporal_month &lt;- dt_temporal |&gt; group_by(Month, first_day_of_month, Week_day) |&gt; summarise(total_accidents = n())\n\ndt_temporal_Year_month &lt;- dt_temporal |&gt; group_by(Year, Month, first_day_of_month, Week_day) |&gt; summarise(total_accidents = n())\n\n# Getting the first and last date in the data\nstart_date = min(dt_temporal$Crash_Date)\nend_date = max(dt_temporal$Crash_Date)\n\n\n\n5.1.1 Create Weekly car-accident data\nWe wish to analyze the weekly trends of total number of car accidents in Montgomery county. In order to do so, we group the data by weeks and sum the number of accidents. Then we aggregarte the data again by Month to have the average weekly car accidents for every year-month combination. We plot this as a black line. At the same time we plot a time series line plot for each holiday-day category –&gt; that is, every holiday has a line + points representing the total number of accidents that happened in the **week* of that holiday. Finally we can use the graph to compare between the total number of accidents in the different weeks of the years and see if a given holiday is able to “increase” or “decrease” the total number of accidents in the week it was celebrated at.\n\n\nCode\ndate_sequence &lt;- seq(as.Date(\"2014-12-28\"), end_date, by = \"week\")\ndt_temporal$Crash_week &lt;- cut(dt_temporal$Crash_Date, breaks = c(date_sequence, Inf), labels = as.factor(date_sequence), include.lowest = TRUE)\n\ndt_temporal_red &lt;- dt_temporal %&gt;%\n  filter(Crash_Date &gt; as.Date(\"2013\", format = '%Y')) %&gt;%\n  group_by(Crash_week) %&gt;%\n  mutate(Count_week = n()) %&gt;%\n  arrange(Crash_week)\n\n#Create a new table to remove the iteration where there are multiple time the same combination for the columns Crash_week and Count_week.\ndt_temporal_week &lt;- dt_temporal_red %&gt;%\n  distinct(Crash_week, Count_week, .keep_all = TRUE)%&gt;%\n  mutate(Crash_week = as.Date(Crash_week, format = \"%Y-%m-%d\")) %&gt;%\n  mutate(Crash_month = month(Crash_week))\n\n### The first and last week in the data aren't complete - they include less than 7 days, so we wish to remove them from the  plot\ndt_temporal_week_without_first_last_week &lt;- filter(dt_temporal_week, Crash_week!=dt_temporal_week$Crash_week[1] & Crash_week!=dt_temporal_week$Crash_week[nrow(dt_temporal_week)])\n\n\n\n\nCode\n# Create a new column for the week of the year\n# Step 1: Create a data frame with all days in the year\nall_days &lt;- data.frame(date = seq(min(dt_temporal$Crash_Date), max(dt_temporal$Crash_Date), by = \"days\"))\n\n# Step 2: Merge the data frames based on the week\nmerged_df &lt;- inner_join(all_days, holiday_data, by = \"date\")\n\n# Step 3: Create a new column \"Is_Holiday\" based on the merging results\nmerged_df$is_holiday &lt;- ifelse(!is.na(merged_df$is_holiday), \"Yes\", \"No\")\nmerged_dy_for_temporal_day &lt;- merged_df\n\nmerged_df$first_day_of_week_new &lt;- floor_date(merged_df$date, \"week\")\nmerged_df$weekday1 &lt;- weekdays(merged_df$first_day_of_week)\n\nresult_df &lt;- merged_df %&gt;%\n  group_by(first_day_of_week_new) %&gt;%\n  summarise(is_holiday = if (\"Yes\" %in% is_holiday) \"Yes\" else \"No\",\n            holiday= first(Holiday))\n\n\nWe display here a time-series graph describing the total number of accidents per week throught 2015-2023.\n\n\nCode\ndt_temporal_week &lt;- left_join(dt_temporal_week_without_first_last_week, result_df, by = c(\"Crash_week\" = \"first_day_of_week_new\"))\n\ndt_temporal_week &lt;- mutate(dt_temporal_week, is_holiday = ifelse(is.na(is_holiday), \"No\", is_holiday))\n\ndt_temporal_week_only_holiday &lt;- dt_temporal_week |&gt; filter(is_holiday == \"Yes\")\n\n####################################\ndt_temporal_week_average_by_month &lt;- dt_temporal_week |&gt; group_by(Year, Month) |&gt;\n  summarise(Count_week = mean(Count_week),\n            Crash_week = min(Crash_week),\n            holiday = \"mean_month\")\n\ndata_for_plot &lt;- rbind(dt_temporal_week_only_holiday|&gt; select(Year, Month, Crash_week, Count_week, holiday),\n      dt_temporal_week_average_by_month)\n\n\nggplot(data_for_plot |&gt; filter(holiday != \"mean_month\"), ) +\n  geom_line(aes(group=holiday, x = Crash_week, y = Count_week, color = holiday), size = 0.4)+\n      geom_point(aes(color = holiday,x = Crash_week, y = Count_week)) +\n  geom_line(data = data_for_plot|&gt; filter(holiday==\"mean_month\"),aes(x = Crash_week, y = Count_week)) +\n  labs(title = \"Weekly Car accidents per holiday\",\n       subtitle = \"The black line is an average of accidents per month\",\n       x = \"Year\", y=\"Total Accidents in a given week\")\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n5.1.2 Using the graph we can get some interesting insights:\n\nFirst, looking at the black line, which represents the average accidents over a period of month (over the years), we can see the car-accidents is a time-series with a trend of decrease (that can be attributed to the Covid-19 outbreak) and seasonality\nThe Veterans Day and Columbus Day tend to have higher amount of car accidents compared to the other holidays and compared to the average car accidents.\nSurprisingly, the Independence day has relatively lower car accidents compared to the average car accidents\nAdditionally, there is a noticeable decline in the number of car accidents observed between 2020 and 2021. This decrease can be attributed to the impact of the COVID-19 outbreak, which resulted in extensive lockdowns and a substantial reduction in the presence of drivers on the roads. Subsequent to this period, the average number of accidents has remained slightly lower than the pre-COVID levels. It is worth noting that we generated box plots for each year, illustrating the total crashes per day. Due to space constraints, we won’t present them here, but it is important to highlight our observations. For the years 2015 to 2019, the box plots exhibited remarkable similarity, indicating comparable sizes of the interquartile range (IQR), Q1, Q3, and median. However, the box plot for 2020 stood out as notably lower than the preceding years. Furthermore, the box plots for 2021 and beyond were lower than those before 2020 but higher than the values observed in 2020.\n\n\n\n5.1.3 Create daily car-accident data\nBefore displaying time-series graph of the daily car accidents, we wish to Plot decomposition graph for the daily time-series. The decomposition graph displays the different components of the daily number of accidents time-series.\n\n\nCode\ndt_temporal_day &lt;- dt_temporal |&gt; group_by(Year, Month, Crash_Date) |&gt; summarise(total_crash = n())\n\ndt_temporal_day &lt;- left_join(dt_temporal_day, merged_dy_for_temporal_day, by = c(\"Crash_Date\"= \"date\"))\n\n### ts daily data\nts_data &lt;- ts(data = dt_temporal_day$total_crash, start = c(2015,1,3), end = c(2023,11,13), frequency = 365)\nplot(decompose(ts_data))\n\n\n\n\n\nThe decomposition graph for the daily number of accidents time series, reveals there is a clear seasonality in the accidents data, that is - there are some cyclical patterns.\n\n\n5.1.4 Average number of car accidents per day of month over the years\n\n\nCode\ndt_temporal_day &lt;- mutate(dt_temporal_day,crash_day_no_year = format(Crash_Date, \"%m-%d\"))\n\nMonth_list &lt;-  c(\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\")\n\n##################################### data for d3 - mean crash per day over years\nc &lt;- dt_temporal_day |&gt; filter(Year!=2020 & Year&lt;2023)|&gt; group_by(Month, crash_day_no_year) |&gt; summarise(total_crash = mean(total_crash)) |&gt;  mutate(day_only = factor(substr(crash_day_no_year, 4, 5)))\nwrite_csv(c, \"data/mean_crash_per_day_over_years.csv\")\n\n\n###########################################################\n### let's see how this graph should look like in d3:\nb &lt;- dt_temporal_day |&gt; filter(Year!=2020 & Year&lt;2023)|&gt; filter(Month %in%Month_list[1:12]) |&gt; group_by(Month, crash_day_no_year) |&gt; summarise(total_crash = mean(total_crash)) |&gt;  mutate(day_only = factor(substr(crash_day_no_year, 4, 5)))\n  \n# Create the plot\nggplot(b, aes(x = day_only, y = total_crash, color = Month, group=Month)) +\n  geom_point() +\n  geom_line(size = 0.35)+\n  #facet_grid(Month~., scales = \"free_x\", space = \"free_x\") +\n  labs(title = \"Average number of car accidents per Month over the years\",\n       subtitle = \"Not including 2020 and 2023\",\n       x = \"Day of Month\", y = \"Average number of car accidents\") \n\n\n\n\n\nAverage number of accidents per day of month over the years reveals a unique “trend” for each month. There are month a higher average of accidents on specific days then others. For example, the 4th of July has typically lower values than 4th of other months. The 1st of Dec has, on average more accidents than the the 1st of the other months, it is quite surprising the the 1st of January, the “new-year” day has the lowest average car accidents compared to the other months, (Maybe there is higher police enforcement leading to this outcome?) In the same notion, the 2nd and 3rd of Novemeber May tend to have, on average, more accidents than the 2nd and 3rd of other month. We also plot this graph in D3."
  },
  {
    "objectID": "results.html#study-of-the-influence-of-the-characteristics-of-the-roads-on-the-number-of-accident-and-hitrun",
    "href": "results.html#study-of-the-influence-of-the-characteristics-of-the-roads-on-the-number-of-accident-and-hitrun",
    "title": "3  Results",
    "section": "5.1 Study of the influence of the characteristics of the roads on the number of accident and Hit/Run",
    "text": "5.1 Study of the influence of the characteristics of the roads on the number of accident and Hit/Run\n\n\nCode\n# ## Explore the Categorical data we have\n# \n# dt_lane &lt;- data_crash[,c(\"Hit_Run\",\"Route_Type\",\"Number_of_Lanes\",\"NonTraffic\",\"Road_Grade\",\"At_Fault\",\"Cross_Street_Type\",\"Collision_Type\",\"Traffic_Control\",\"Driver_Substance_Abuse\",\"Road_Alignment\",\"Junction\",\"Road_Condition\",\"Road_Division\",\"First_Harmful_Event\",\"Light\",\"Surface_Condition\")]\n# \n# unique_values &lt;- lapply(dt_lane, unique)\n# \n# # Print unique value for each of the column\n# for (col_name in names(unique_values)) {\n#   cat(\"Column:\", col_name, \"\\n\")\n#   print(unique_values[[col_name]])\n#   cat(\"\\n\")\n# }\n\n\n\n\nCode\n## Create 2 new datasets to explore different Categorical values\ndt_lane &lt;- data_crash[,c(\"Road_Division\", \"Junction\", \"Road_Alignment\" ,\"Traffic_Control\",\"Road_Name\",\"Number_of_Lanes\",\"Hit_Run\",\"Longitude\",'Latitude')]\n\ndt_responsible &lt;- data_crash[,c(\"Hit_Run\",\"NonTraffic\",\"At_Fault\",\"Driver_Substance_Abuse\")]\n\n\n\n\nCode\n#Rename the column in Road_type and get rid of the Na and the unknown values\ndt_lane &lt;- dt_lane %&gt;%\n  mutate(Road_Division = recode(Road_Division,\n        \"TWO-WAY, NOT DIVIDED WITH A CONTINUOUS LEFT TURN\" = \"2-way, not divided\",\n        \"TWO-WAY, NOT DIVIDED\" = \"2-way, not divided\",\n        \"TWO-WAY, DIVIDED, POSITIVE MEDIAN BARRIER\" = '2-way, divided',\n        \"TWO-WAY, DIVIDED, UNPROTECTED PAINTED MIN 4 FEET\" = '2-way, divided',\n        \"ONE-WAY TRAFFICWAY\" = '1-way',\n        \"OTHER\" = 'Other')) %&gt;%\n  filter(Road_Division != 'UNKNOWN') %&gt;%\n  filter(Road_Division != 'Other') %&gt;%\n  na.omit()\n\n# #Change the column Number of Lanes to remove the lanes with more than 6 lanes\n# dt_lane &lt;- dt_lane %&gt;%\n#   filter(Number_of_Lanes &lt; 7) %&gt;%\n#   filter(Number_of_Lanes != 0)\n#   \n# # Change the order of factor \n# dt_lane$Road_Division &lt;- factor(dt_lane$Road_Division, levels = c(\"1-way\", \"2-way, not divided\", \"2-way, divided\", 'Other'))\n# \n# \n# ggplot(dt_lane, aes(y=Road_Division))+\n#   geom_bar() +\n#   facet_grid(Number_of_Lanes~.)+\n#   #theme(axis.text.x = element_text(angle = 45, hjust = 1))+\n#   labs(title ='Facet by number of Lanes' )\n# &lt;u&gt;Comment :&lt;/u&gt; One can see that most of the accidents that happends on 3 lanes road are 2-way and divided (most likely highway). \n\n\n\n5.1.1 Traffic Control\n\n\nCode\ndt_lane &lt;- dt_lane %&gt;%\n   mutate(Traffic_Control = recode(Traffic_Control,\n        \"FLASHING TRAFFIC SIGNAL\" = \"Traffic Light\",\n        \"TRAFFIC SIGNAL\" = \"Traffic Light\",\n        \"NO CONTROLS\" = 'No Sign',\n        \"RAILWAY CROSSING DEVICE    \" = 'Warning Sign',\n        \"WARNING SIGN\" = 'Warning Sign',\n        \"SCHOOL ZONE SIGN DEVICE\" = 'Warning Sign',\n        \"YIELD SIGN\" = 'Warning Sign',\n        \"STOP SIGN\" = 'Stop Sign',\n        .default  = 'Other')) %&gt;%\n  filter(!is.na(Traffic_Control))\n\nlane_freq &lt;- dt_lane %&gt;%\n  count(Traffic_Control, name = \"Frequency_control\")\ndt_lane &lt;- left_join(lane_freq, dt_lane, by = \"Traffic_Control\")\n  \n# ggplot(dt_lane, aes(x = reorder(Traffic_Control, -Frequency_control))) +\n#   geom_bar() +\n#   labs(title = \"Bar Plot of Junction Types with Count\", x = \"Junction Type\", y = \"Count\") +\n#   theme_minimal()  # Adjust the theme if needed\n\n\n\n\n5.1.2 Junction\n\n\nCode\ndt_lane &lt;- dt_lane %&gt;%\n  mutate(Junction = recode(Junction,\n        \"INTERSECTION\" = \"Intersection\",\n        \"INTERSECTION RELATED\" = \"Intersection\",\n        \"NON INTERSECTION\" = 'Non Intersection',\n        \"OTHER DRIVEWAY\" = 'Driveway',\n        \"COMMERCIAL DRIVEWAY\" = 'Driveway',\n        \"ALLEY\" = 'Driveway',\n        \"CROSSOVER RELATED\" = \"Crossover\",\n        \"INTERCHANGE RELATED\" = \"Interchange\",\n        \"RESIDENTIAL DRIVEWAY\" = 'Driveway',\n        \"RAILWAY GRADE CROSSING\"= 'Other',\n        \"OTHER\" = 'Other')) %&gt;%\n  filter(Junction != 'UNKNOWN') %&gt;%\n  filter(Junction != 'Other') %&gt;%\n  na.omit() \n\nlane_freq &lt;- dt_lane %&gt;%\n  count(Junction, name = \"Frequency_junc\")\ndt_lane_freq &lt;- left_join(lane_freq, dt_lane, by = \"Junction\")\n\nggplot(dt_lane_freq, aes(x = reorder(Junction, -Frequency_junc))) +\n  geom_bar(aes(fill = Traffic_Control)) +\n  labs(title = \"Relation between Junction Types and Traffic Control sign\", x = \"Junction Type\", y = \"Count\", fill = \"Signalisation for Traffic\") +\n  scale_fill_viridis_d() +\n  theme_minimal()  # Adjust the theme if needed\n\n\n\n\n\n\nWe can observe that most of the car accidents happen at an intersection. Further, half of the crashes at these intersection have traffic lights. This highlights an important issue : traffic light are not sufficient to mitigate the risk of car accident. Despite not having the proportion of number of cars crossing intersection with traffic light vs the number of car crossing intersection without traffic light this indicates that traffic light are not efficient for reducing car accident.\n\n\n\nCode\n# dt_lane_freq_intersection &lt;- dt_lane_freq %&gt;%\n#   filter(Junction == 'Intersection')\n# \n# # Function to filter rows within a certain radius\n# filter_within_radius &lt;- function(data, radius_meters = 100) {\n#   n &lt;- nrow(data)\n#   keep_rows &lt;- rep(FALSE, n)\n# \n#   # Initialize with the first row\n#   keep_rows[1] &lt;- TRUE\n# \n#   for (i in 2:n) {\n#     distances &lt;- geosphere::distVincentySphere(\n#       data[i, c(\"Longitude\", \"Latitude\")],\n#       data[keep_rows, c(\"Longitude\", \"Latitude\")]\n#     )\n# \n#     too_close &lt;- distances &lt; radius_meters\n#     keep_rows[i] &lt;- !any(too_close)\n#   }\n# \n#   return(data[keep_rows, , drop = FALSE])\n# }\n# \n# \n# # Apply the function to your data\n# dt_lane_freq_filtered &lt;- filter_within_radius(dt_lane_freq_intersection, radius_meters = 100)\n\n\n\n\n5.1.3 Alluvial plot to see pattern\n\n\nCode\ndt_lane1 &lt;- dt_lane[,c('Road_Division', 'Junction', 'Traffic_Control','Road_Name','Hit_Run')]\n\nn_threshold = 100 \ndt_lane1 &lt;- dt_lane1 %&gt;%\n  group_by(Road_Division, Junction, Traffic_Control) %&gt;%\n  mutate(Frequency = n()) %&gt;%\n  ungroup() %&gt;%\n  filter(Frequency &gt;= n_threshold) %&gt;%\n  distinct(Road_Division, Junction, Traffic_Control, .keep_all = TRUE)\n\n# Map_pt &lt;- dt_lane1$Road_Name\n# Map_pt\n\n\n\n\nCode\njunction_order &lt;- c(\"Crossover\", \"Intersection\", \"Driveway\",\"Non Intersection\", \"Interchange\")\n\n# Reorder the Junction variable in the dataset\ndt_lane1 &lt;- dt_lane1 %&gt;%\n  mutate(Junction = factor(Junction, levels = junction_order))\n\n# Plot the alluvial diagram\n\nggplot(data = dt_lane1,\n       aes(axis1 = Road_Division, axis2 = Traffic_Control, axis3 = Junction, axis4= Hit_Run, y = Frequency)) +\n  geom_alluvium(aes(fill = Hit_Run)) +\n  geom_stratum() +\n  geom_text(stat = \"stratum\",\n            aes(label = after_stat(stratum))) +\n  #scale_x_discrete(limits = c(\"Road Division\", \"Traffic Signal\", \"Junction type\"),\n                   #expand = c(0.15, 0.05, 0.05)) +\n  scale_fill_brewer(type = \"seq\", palette = \"PuRd\") +\n  labs(title = 'Alluvial plot combining characteristics about the crash location and the Hit/Run situation', fill= 'Hit/Run')+\n  theme_void()\n\n\n\n\n\nComments : The alluvial plots assist us in visualizing the most common scenarios leading to Hit & Run incidents. Indeed, the majority of these incidents occur on undivided two-way roads at non-intersections with no traffic controls. This visible pattern in the scenario of Hit/Run can be f # Ethan - what did you want to write here?"
  },
  {
    "objectID": "data.html#technical-description",
    "href": "data.html#technical-description",
    "title": "2  Data",
    "section": "2.1 Technical Description",
    "text": "2.1 Technical Description\nThe data we are analyzing in this project is provided by the Public-Safety website of the Montgomery County, MD link\nThe data is supplied by all the police departments of this county. Moreover, the description of the data set mentions that : “Please note that these collision reports are based on preliminary information supplied to the Police Department by the reporting parties. Therefore, the collision data available on this web page may reflect:\n\nInformation not yet verified by further investigation\nInformation that may include verified and unverified collision data\nPreliminary collision classifications may be changed at a later date based upon further investigation\nInformation may include mechanical or human error”\n\nThe above impose some limitations using the data.\nAs outlined in the dataset description, the data undergoes weekly updates. The source dataset comprises 44 columns and 95.6k rows, each representing a distinct car collision (car accident). The dataset encompasses geographical, numerical, categorical, and date-time information.\nThe dataset, which we acquired on November 22, 2023, is accessible as a .csv file in the GitHub repository under the ‘data’ directory. For the purposes of this project, we conducted an analysis of the data up until that date. It is important for readers of this project to note that while our work can be replicated and extended with updated information, there may be a necessity for additional preprocessing to address novel issues that may have arisen after November 2023. Furthermore, some conclusions might need to be revisited and updated based on the latest data.\nTo reiterate, all analyses presented in this work are based on data available until November 22, 2023.\n\n2.1.1 Holiday data\nWe understood there could be some special significant to some days during the year - those are the holidays in the american calendar. We assume the number of car accident might be influenced by the fact there is a holiday (and maybe more/less people will drive and/or people might be more likely to drink and drive or act in a more dangerous/safe manner)\nTo get the dates of these holidays we used a dataset from Microsoft Azure that we downloaded using Python Visit Microsoft Azure Open Datasets. We filtered the relevant rows for our study (took dates between 2015 and 2023) and created the holiday_data data frame.\n\n\nCode\nholiday_data &lt;- readr::read_csv(\"data/holiday_dates.csv\")\nholiday_data &lt;- holiday_data |&gt; filter(countryOrRegion == \"United States\") |&gt; select(c(normalizeHolidayName,isPaidTimeOff, date)) \n\nholiday_data$is_holiday &lt;- \"Yes\"\nholiday_data &lt;- holiday_data |&gt; rename(\"Holiday\" = \"normalizeHolidayName\")"
  },
  {
    "objectID": "data.html#research-plan",
    "href": "data.html#research-plan",
    "title": "2  Data",
    "section": "2.2 Research Plan",
    "text": "2.2 Research Plan\nIn this course, we were introduced to various types of plots, and we intend to leverage these visualizations to uncover factors contributing to a higher number of collisions (car accidents) in the Montgomery county.\nAs stated in the introduction, we divide the analysis into three parts:\nFirstly, our exploration will focus on time-series analysis of the Crash Date/Time to identify potential trends, seasonality and key insights in the collision data. We aim to investigate whether there is a fluctuation in the number of accidents during specific months, days of the week, or hours of the day as well as compare these between the different years. Additionally, we are interested in understanding if holidays or weeks with holidays exhibit a distinct pattern in terms of accident frequency. To enable that analysis, we downloaded holiday data which presents the american holiday-dates in each year, and we merge this information with the data we exported from the public safety website of the Montgomery county.\nOur second area of inquiry addresses the pressing issue of hit-and-run accidents. Utilizing the available data, we plan to examine the correlation between various features and the Hit-Run column. For example, We use mosaic plots for exploring relationships, associations and patterns within the Hit-Run variable to other categorical variables. Insights gained from this analysis could contribute to a better understanding of the Hit and Run type of accident problem and provide recommendations for policymakers to mitigate it.\nLastly, we will employ geographical, or spatial, data to explore the relationship between accident density and geographical attributes. Specifically, we aim to identify roads with the highest concentration of accidents and analyze common attributes among them. This analysis may uncover patterns or characteristics that could inform recommendations for reducing accidents in these locations. Our approach involves utilizing spatial data to gain deeper insights into both “regular” accidents and “Hit and Run” incidents.\nOverall, our goal is to identify combinations of features that could elevate the risk of collisions. This information can then provide policymakers with valuable insights to implement meaningful changes or restrictions on the roads."
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "5  Conclusion",
    "section": "",
    "text": "Discuss: main takeaways of your exploration, limitations, future directions, lessons learned.\nIn the course of our project, we conducted a comprehensive analysis of car collision data in Montgomery County, extracting valuable insights outlined in detail in the results chapter.\n\n5.0.0.1 Time Series Analysis\nIn our examination of the time series aspect concerning the date and time of collisions, we identified notable patterns associated with specific holidays - there are some holidays that typically correspond to weeks with higher/lower number of accidents. Our recommendation to Montgomery Police Department is to increase the presence of officers during weeks corresponding to holidays such as Veterans Day and Columbus Day. While the analysis did not reveal a significant connection between a given month and the number of accidents, it highlighted a substantial correlation between the day of the week and the hour of the day with accident frequencies. Notably, weekends and late hours exhibited lower accident numbers, aligning with the expected lower volume of drivers during these periods.\n\n\n5.0.0.2 Hit-and-Run Incidents Analysis\nWithin the scope of the Hit-and-Run Incidents analysis we found out there is a higher proportion of Hit-Run accident on weekends and on late hours. That is, if an accident happen to occur at the middle of the week and or at an early time of the day, there is less chance the driver will run away after an accident. This finding prompted recommendations for enhanced road enforcement during these periods, including the consideration of strategic placements of “fake police cars” at potentially risky intersections to deter hit-and-run incidents. In addition, we discovered that accidents of the type “parked vehicle” - that is accidents where the driver hit a vehicle that was parking, has more than half chance to hit and run (compared to the overall proportion of hit-run accidents). We suggest encouraging people to install a camera in there car that works 24/7 and is able to record such incidents. If enough drivers will do that, drivers in general will be afraid to hit parked vehicles and run away since they would know they would probably get caught and get a more significant punishment.\nFinally, Utilizing an alluvial diagram, we uncovered a notable association, indicating that roads configured as two-ways without a central division and lacking traffic controls exhibit the highest likelihood of hit-and-run accidents. We recommend an escalation of enforcement measures on such roads, with one potential solution being the strategic installation of security cameras in identified problematic areas.\nWe suggest the police department to increase enforcement in such roads - one option is to install security camera in those problematic areas. We would like to note we have some hypothesis regarding this phenomena: Roads without traffic controls (such as stop signs or traffic signals) may lack regulated intersections, potentially leading to uncontrolled interactions between vehicles. The absence of clear right-of-way rules can contribute to chaotic traffic situations, increasing the risk of accidents, including hit-and-run cases, moreover, Roads without physical divisions may provide more opportunities for drivers involved in accidents to flee the scene. The absence of barriers or medians makes it easier for a driver to quickly leave the area without being easily identified. However we want to emphasize that correlation cannot be interpreted as causation, so we can only try to reason about our findings, but we don’t have the necessary data and tools to test those assumptions.\n\n\n5.0.0.3 Geospatial Exploration\nWithin the scope of the Geospatial Exploration we analyzed a heat-map of the accidents in general and the accidents of hit-run type.\n—————— draft: In this project we analyzed car collision data in the Montgomery County. We crafted some valuable insights which were presented in elaboration in the results chapter.\nWithin the scope of the time series analysis on the date/time of the collision, We discovered there are some holidays that usually corresponds to weeks with higher/lower number accident. We advise Montgomery police department to increase presense of police officers in the week of Veterans Day and Columbus days. We found there isn’t a significant connection between a given month and the number of accidents, however the day of week and the hour of the day has a great correlation with the number of accidents. Weekends and late hours of the day typically habe lower number of accidents compared to the middle of the week and the middle-day hours. This is reasonable as the number of drivers on the road is higher at those times.\nWithin the scope of the Hit-and-Run Incidents analysis we found out there is a higher proportion of Hit-Run accident on weekends and on late hours. That is, if an accident happen to occur at the middle of the week and or at an early time of the day, there is less chance the driver will run away after an accident. From that we can learn Montgomery police department need to increase the road-enforcment on wekeends and in later-hours. We suggest considering placment of “fake police cars” (without poice officers) in various dangerous intersectinos to lower the chances of hit-run accident in particular and of accidents at general.\nIn addition, we discovered that accidents of the type “parked vehicle” - that is accidents where the driver hitted a vehicle that was parking, has more than half chance to hit and run (compared to the overall proportion of hit-run accidents). We suggest incoruaging people to install a camera in there car that works 24/7 and is able to record such incidents. If enough number of drivers will do that, drivers in general will be afraid to hit and run away since they would know they would probably get cuaght and get a more severe punsihment.\nFinally, using allovial diagram, we discovered that roads that are 2 ways without a division between them and without any control signs have the highest chance of hit and run accident. We suggest the police department to increase enforcment in such roads - one option is to install security camera in those problematic areas. We would like to note we have some hypothesis regarding this phenomena: Roads without traffic controls (such as stop signs or traffic signals) may lack regulated intersections, potentially leading to uncontrolled interactions between vehicles. The absence of clear right-of-way rules can contribute to chaotic traffic situations, increasing the risk of accidents, including hit-and-run cases, moreover, Roads without physical divisions may provide more opportunities for drivers involved in accidents to flee the scene. The absence of barriers or medians makes it easier for a driver to quickly leave the area without being easily identified. However we want to emphasize that correlation cannot be interpeted as causation, so we can only try to reason about our findings, but we don’t have the necessary data and tools to test those assumptions.\nthat in the rest of the week, moreover,\nplot: (D3) Average number of accidents per day of month over the years Average number of accidents per day of month over the years reveals a unique “trend” for each month. There are month a higher average of accidents on specific days then others. For example, the 4th of July has typically lower values than 4th of other months. In the same notion, the 2nd and 3rd of May tend to have, on average, more accidents than the 2nd and 3rd of other month.\nWe saw there is an indicatino of seasonality in the car-accident data, therefore we can advice building a time-series forecasting model that will try to predict, for given roads"
  },
  {
    "objectID": "results.html#part-1---time-series-analysis",
    "href": "results.html#part-1---time-series-analysis",
    "title": "3  Results",
    "section": "3.1 Part 1 - Time Series Analysis",
    "text": "3.1 Part 1 - Time Series Analysis\nWe begin our analysis with time-series analysis. In order to perform this examination, we take the date-time column Crash_Date_Time and extract from it the date, Year, Month, weekday, time, hour, etc. of the accident. Then we aggregate the data according to one or more of the date-time new columns to get the total number of accident within that time-frame. Finally we observe the time-series of the number of accident with respect to a given date/time dimension.\nWe understood there could be some special significant to some days during the year - those are the holidays in the american calendar. We assume the number of car accident might be influenced by the fact there is a holiday (and maybe more/less people will drive and/or people might be more likely to drink and drive or act in a more dangerous/safe manner)\nTo get the dates of these holidays we used a dataset from Microsoft Azure that we downloaded using Python Visit Microsoft Azure Open Datasets. We filter the relevant rows for our study (took dates between 2015 and 2023)\n\n3.1.1 Preprocess the Date-Time column\nHere we take the date/time column and transform it into the right data type as well as create some distinct date/time columns that will help us investigate and explore the data (time series analysis)\n\n\nCode\ndt_temporal &lt;- dplyr::select(data_crash,c(\"Crash_Date_Time\",\"Weather\", \"Hit_Run\",\n                       \"First_Harmful_Event\", \"At_Fault\"))\n\n#Separate time and Date\ndt_temporal$\"Crash_Date_Time\" &lt;- as.POSIXct(dt_temporal$\"Crash_Date_Time\", format = \"%m/%d/%Y %I:%M:%S %p\", tz = \"America/New_York\")\n\ndt_temporal$Crash_Date &lt;- as.Date(dt_temporal$\"Crash_Date_Time\", tz = \"America/New_York\")\n\ndt_temporal$Crash_Time &lt;- format(dt_temporal$\"Crash_Date_Time\", \"%H:%M:%S\")\ndt_temporal$Crash_Time &lt;- as_hms(dt_temporal$Crash_Time)\ndt_temporal$Crash_Hour &lt;- hour(dt_temporal$Crash_Time) #Crash hour\n\n\n### add some \"date slicers\" columns\ndt_temporal$Week_day &lt;- weekdays(dt_temporal$Crash_Date)\ndt_temporal$Month &lt;-  months(dt_temporal$Crash_Date)\ndt_temporal$Year &lt;-  year(dt_temporal$Crash_Date)\ndt_temporal$first_day_of_month &lt;- as.Date(format(dt_temporal$Crash_Date, \"%Y-%m-01\"))\n\n\n### Transform some columns to factors --&gt; for visualization purpose\ndt_temporal &lt;- mutate(dt_temporal, Week_day = factor(Week_day,\n                                                     levels = c(\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\")))\n\ndt_temporal &lt;- mutate(dt_temporal, Month = factor(Month,\n                                                     levels = c(\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\"July\", \"August\", \"September\", \"October\", \"November\", \"December\")))\n\n# dt_temporal$Month &lt;- factor(dt_temporal$Month, \n#                           levels = c(\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\"July\", \"August\", \"September\", \"October\", \"November\", \"December\"),)\n\n### arrange the data by date\ndt_temporal &lt;- dt_temporal |&gt; arrange(Crash_Date)\n\ndt_temporal_month &lt;- dt_temporal |&gt; group_by(Month, first_day_of_month, Week_day) |&gt; summarise(total_accidents = n())\n\ndt_temporal_Year_month &lt;- dt_temporal |&gt; group_by(Year, Month, first_day_of_month, Week_day) |&gt; summarise(total_accidents = n())\n\n# Getting the first and last date in the data\nstart_date = min(dt_temporal$Crash_Date)\nend_date = max(dt_temporal$Crash_Date)\n\n### Filtering the holiday dates\n\nholiday_data &lt;- holiday_data |&gt; filter(date &gt;= start_date & date &lt;= end_date)\n\n\n\n\n3.1.2 Create Weekly car-accident data\nWe wish to analyze the weekly trends of total number of car accidents in Montgomery county. In order to do so, we group the data by weeks and sum the number of accidents. Then we aggregarte the data again by Month to have the average weekly car accidents for every year-month combination. We plot this as a black line. At the same time we plot a time series line plot for each holiday-day category –&gt; that is, every holiday has a line + points representing the total number of accidents that happened in the week of that holiday. Finally we can use the graph to compare between the total number of accidents in the different weeks of the years and see if a given holiday is able to “increase” or “decrease” the total number of accidents in the week it was celebrated at.\n\n\nCode\ndate_sequence &lt;- seq(as.Date(\"2014-12-28\"), end_date, by = \"week\")\ndt_temporal$Crash_week &lt;- cut(dt_temporal$Crash_Date, breaks = c(date_sequence, Inf), labels = as.factor(date_sequence), include.lowest = TRUE)\n\ndt_temporal_red &lt;- dt_temporal %&gt;%\n  filter(Crash_Date &gt; as.Date(\"2013\", format = '%Y')) %&gt;%\n  group_by(Crash_week) %&gt;%\n  mutate(Count_week = n()) %&gt;%\n  arrange(Crash_week)\n\n#Create a new table to remove the iteration where there are multiple time the same combination for the columns Crash_week and Count_week.\ndt_temporal_week &lt;- dt_temporal_red %&gt;%\n  distinct(Crash_week, Count_week, .keep_all = TRUE)%&gt;%\n  mutate(Crash_week = as.Date(Crash_week, format = \"%Y-%m-%d\")) %&gt;%\n  mutate(Crash_month = month(Crash_week))\n\n### The first and last week in the data aren't complete - they include less than 7 days, so we wish to remove them from the  plot\ndt_temporal_week_without_first_last_week &lt;- filter(dt_temporal_week, Crash_week!=dt_temporal_week$Crash_week[1] & Crash_week!=dt_temporal_week$Crash_week[nrow(dt_temporal_week)])\n\n\n\n\nCode\n# Create a new column for the week of the year\n# Step 1: Create a data frame with all days in the year\nall_days &lt;- data.frame(date = seq(min(dt_temporal$Crash_Date), max(dt_temporal$Crash_Date), by = \"days\"))\n\n# Step 2: Merge the data frames based on the week\nmerged_df &lt;- inner_join(all_days, holiday_data, by = \"date\")\n\n# Step 3: Create a new column \"Is_Holiday\" based on the merging results\nmerged_df$is_holiday &lt;- ifelse(!is.na(merged_df$is_holiday), \"Yes\", \"No\")\nmerged_dy_for_temporal_day &lt;- merged_df\n\nmerged_df$first_day_of_week_new &lt;- floor_date(merged_df$date, \"week\")\nmerged_df$weekday1 &lt;- weekdays(merged_df$first_day_of_week)\n\nresult_df &lt;- merged_df %&gt;%\n  group_by(first_day_of_week_new) %&gt;%\n  summarise(is_holiday = if (\"Yes\" %in% is_holiday) \"Yes\" else \"No\",\n            holiday= first(Holiday))\n\n\nWe display here a time-series graph describing the total number of accidents per week throught 2015-2023.\n\n\nCode\ndt_temporal_week &lt;- left_join(dt_temporal_week_without_first_last_week, result_df, by = c(\"Crash_week\" = \"first_day_of_week_new\"))\n\ndt_temporal_week &lt;- mutate(dt_temporal_week, is_holiday = ifelse(is.na(is_holiday), \"No\", is_holiday))\n\ndt_temporal_week_only_holiday &lt;- dt_temporal_week |&gt; filter(is_holiday == \"Yes\")\n\n####################################\ndt_temporal_week_average_by_month &lt;- dt_temporal_week |&gt; group_by(Year, Month) |&gt;\n  summarise(Count_week = mean(Count_week),\n            Crash_week = min(Crash_week),\n            holiday = \"mean_month\")\n\ndata_for_plot &lt;- rbind(dt_temporal_week_only_holiday|&gt; select(Year, Month, Crash_week, Count_week, holiday),\n      dt_temporal_week_average_by_month)\n\n\nggplot(data_for_plot |&gt; filter(holiday != \"mean_month\"), ) +\n  geom_line(aes(group=holiday, x = Crash_week, y = Count_week, color = holiday), size = 0.4)+\n      geom_point(aes(color = holiday,x = Crash_week, y = Count_week)) +\n  geom_line(data = data_for_plot|&gt; filter(holiday==\"mean_month\"),aes(x = Crash_week, y = Count_week), size = 0.7) +\n  labs(title = \"Weekly Car accidents per holiday\",\n       subtitle = \"The black line is an average of accidents per month\",\n       x = \"Year\", y=\"Total Accidents in a given week\")\n\n\n\n\n\n\n\n3.1.3 Using the graph we can get some interesting insights:\n\nFirst, looking at the black line, which represents the average accidents over a period of month (over the years), we can see the car-accidents is a time-series with a trend of decrease (that can be attributed to the Covid-19 outbreak) and seasonality\nThe Veterans Day and Columbus Day tend to have higher amount of car accidents compared to the other holidays and compared to the average car accidents.\nSurprisingly, the Independence day has relatively lower car accidents compared to the average car accidents\nAdditionally, there is a noticeable decline in the number of car accidents observed between 2020 and 2021. This decrease can be attributed to the impact of the COVID-19 outbreak, which resulted in extensive lockdowns and a substantial reduction in the presence of drivers on the roads. Subsequent to this period, the average number of accidents has remained slightly lower than the pre-COVID levels. It is worth noting that we generated box plots for each year, illustrating the total crashes per day. Due to space constraints, we won’t present them here, but it is important to highlight our observations. For the years 2015 to 2019, the box plots exhibited remarkable similarity, indicating comparable sizes of the interquartile range (IQR), Q1, Q3, and median. However, the box plot for 2020 stood out as notably lower than the preceding years. Furthermore, the box plots for 2021 and beyond were lower than those before 2020 but higher than the values observed in 2020.\n\n\n\n3.1.4 Create daily car-accident data\nBefore displaying time-series graph of the daily car accidents, we wish to Plot decomposition graph for the daily time-series. The decomposition graph displays the different components of the daily number of accidents time-series.\n\n\nCode\ndt_temporal_day &lt;- dt_temporal |&gt; group_by(Year, Month, Crash_Date) |&gt; summarise(total_crash = n())\n\ndt_temporal_day &lt;- left_join(dt_temporal_day, merged_dy_for_temporal_day, by = c(\"Crash_Date\"= \"date\"))\n\n### ts daily data\nts_data &lt;- ts(data = dt_temporal_day$total_crash, start = c(2015,1,3), end = c(2023,11,13), frequency = 365)\nplot(decompose(ts_data))\n\n\n\n\n\nThe decomposition graph for the daily number of accidents time series, reveals there is a clear seasonality in the accidents data, that is - there are some cyclical patterns.\n\n\n3.1.5 Average number of car accidents per day of month over the years\n\n\nCode\ndt_temporal_day &lt;- mutate(dt_temporal_day,crash_day_no_year = format(Crash_Date, \"%m-%d\"))\n\nMonth_list &lt;-  c(\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\")\n\n##################################### data for d3 - mean crash per day over years\nc &lt;- dt_temporal_day |&gt; filter(Year!=2020 & Year&lt;2023)|&gt; group_by(Month, crash_day_no_year) |&gt; summarise(total_crash = mean(total_crash)) |&gt;  mutate(day_only = factor(substr(crash_day_no_year, 4, 5)))\nwrite_csv(c, \"data/mean_crash_per_day_over_years.csv\")\n\n###Data for D3\nc |&gt; filter(Month == \"January\") |&gt; write_csv(\"data/data_for_d3/Jan_data.csv\")\nc |&gt; filter(Month == \"February\") |&gt; write_csv(\"data/data_for_d3/Feb_data.csv\")\nc |&gt; filter(Month == \"March\") |&gt; write_csv(\"data/data_for_d3/March_data.csv\")\nc |&gt; filter(Month == \"April\") |&gt; write_csv(\"data/data_for_d3/April_data.csv\")\nc |&gt; filter(Month == \"May\") |&gt; write_csv(\"data/data_for_d3/May_data.csv\")\nc |&gt; filter(Month == \"June\") |&gt; write_csv(\"data/data_for_d3/June_data.csv\")\nc |&gt; filter(Month == \"July\") |&gt; write_csv(\"data/data_for_d3/July_data.csv\")\nc |&gt; filter(Month == \"August\") |&gt; write_csv(\"data/data_for_d3/August_data.csv\")\nc |&gt; filter(Month == \"September\") |&gt; write_csv(\"data/data_for_d3/September_data.csv\")\nc |&gt; filter(Month == \"October\") |&gt; write_csv(\"data/data_for_d3/October_data.csv\")\nc |&gt; filter(Month == \"November\") |&gt; write_csv(\"data/data_for_d3/November_data.csv\")\nc |&gt; filter(Month == \"December\") |&gt; write_csv(\"data/data_for_d3/December_data.csv\")\n\n###########################################################\n### let's see how this graph should look like in d3:\nb &lt;- dt_temporal_day |&gt; filter(Year!=2020 & Year&lt;2023)|&gt; filter(Month %in%Month_list[1:12]) |&gt; group_by(Month, crash_day_no_year) |&gt; summarise(total_crash = mean(total_crash)) |&gt;  mutate(day_only = factor(substr(crash_day_no_year, 4, 5)))\n  \n# Create the plot\nggplot(b, aes(x = day_only, y = total_crash, color = Month, group=Month)) +\n  geom_point() +\n  geom_line(size = 0.35)+\n  #facet_grid(Month~., scales = \"free_x\", space = \"free_x\") +\n  labs(title = \"Average number of car accidents per Month over the years\",\n       subtitle = \"Not including 2020 and 2023\",\n       x = \"Day of Month\", y = \"Average number of car accidents\") \n\n\n\n\n\nAverage number of accidents per day of month over the years reveals a unique “trend” for each month. There are month a higher average of accidents on specific days then others. For example, the 4th of July has typically lower values than 4th of other months. The 1st of Dec has, on average more accidents than the the 1st of the other months, it is quite surprising the the 1st of January, the “new-year” day has the lowest average car accidents compared to the other months, (Maybe there is higher police enforcement leading to this outcome?) In the same notion, the 2nd and 3rd of November May tend to have, on average, more accidents than the 2nd and 3rd of other month.\nNote that We also plot this graph in D3 - the power of D3 in this sense is to enable comparing different months easily. The above graph has too many months displayed all at once, and it could be hard to compare some specific months to each other.\n\n\n3.1.6 Hours of the day\nWe would like to see the number of accidents per hour of day - are there any hours in the day that typically have more accidents than others?\n\n\nCode\n# we only care about the hours not the minutes\ndt_temporal &lt;- dt_temporal %&gt;%\n  mutate(Crash_Time = paste0(substr(Crash_Time, start = 1, stop =2),'h')) \n\nggplot(dt_temporal, aes(x = Crash_Time)) +\n  geom_bar(fill = \"cornflowerblue\", color = \"black\") +\n  geom_text(stat = \"count\", aes(label = ..count..), vjust = -0.5, size = 3) +  # Adjust size as needed\n  labs(title = \"Total number of accidents per day-hour\",\n       x = 'Hours in the day', y = 'Number of Crashes')\n\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n\n\n\n\n\n\nCar crash accidents tend to spike during the work commute hours, particularly between 15:00 to 17:00. This timeframe, associated with the journey back home, is notorious for having a higher number of car on the roads leading to an increased number of accidents. This visualization serves as a reminder for drivers to exercise extra caution on the road during the late afternoon and evening hours. Besides, the data reveals a significant increase in accidents during the afternoon compared to the morning. This pattern suggests that fatigue accumulated throughout the day might influence people’s driving behavior. The increased number of accidents during the afternoon hours serves as a noteworthy observation, emphasizing the potential impact of daily tiredness on driving safety.\n\n\n\n3.1.7 Distribution of the number of accidents by different time-slicers: Month, weekday, hour\nLet’s explore the distribution of daily number of accidents per month, per weekday and per hour. Are the different categories have different distribution of the daily number of accidents?\n\n\nCode\ndt_temporal_1 &lt;- dt_temporal\n# Convert the Month column to display the abbreviation version\n# Create a list of month abbreviations\nmonth_abbreviations &lt;- c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\")\nweekday_labels &lt;- c(\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\")\n\n# Convert the Week_day column to display the abbreviation version\ndt_temporal_1$Week_day &lt;- ifelse(dt_temporal_1$Week_day == \"Sunday\", \"Sun\",\n                             ifelse(dt_temporal_1$Week_day == \"Monday\", \"Mon\",\n                             ifelse(dt_temporal_1$Week_day == \"Tuesday\", \"Tue\",\n                             ifelse(dt_temporal_1$Week_day == \"Wednesday\", \"Wed\",\n                             ifelse(dt_temporal_1$Week_day == \"Thursday\", \"Thu\",\n                             ifelse(dt_temporal_1$Week_day == \"Friday\", \"Fri\",\n                             ifelse(dt_temporal_1$Week_day == \"Saturday\", \"Sat\", dt_temporal_1$Week_day)))))))\n\ndt_temporal_1$Week_day &lt;- factor(dt_temporal_1$Week_day , levels = weekday_labels)\n\n# Convert the Month column to display the abbreviation version\ndt_temporal_1$Month &lt;- ifelse(dt_temporal_1$Month == \"January\", \"Jan\",\n                          ifelse(dt_temporal_1$Month == \"February\", \"Feb\",\n                          ifelse(dt_temporal_1$Month == \"March\", \"Mar\",\n                          ifelse(dt_temporal_1$Month == \"April\", \"Apr\",\n                          ifelse(dt_temporal_1$Month == \"May\", \"May\",\n                          ifelse(dt_temporal_1$Month == \"June\", \"Jun\",\n                          ifelse(dt_temporal_1$Month == \"July\", \"Jul\",\n                          ifelse(dt_temporal_1$Month == \"August\", \"Aug\",\n                          ifelse(dt_temporal_1$Month == \"September\", \"Sep\",\n                          ifelse(dt_temporal_1$Month == \"October\", \"Oct\",\n                          ifelse(dt_temporal_1$Month == \"November\", \"Nov\",\n                          ifelse(dt_temporal_1$Month == \"December\", \"Dec\", dt_temporal_1$Month))))))))))))\n\ndt_temporal_1$Month &lt;- factor(dt_temporal_1$Month, levels = month_abbreviations)\n\ndt_temporal_month &lt;- dt_temporal_1 |&gt; group_by(Month, first_day_of_month, Week_day) |&gt; summarise(total_accidents = n())\n\ndt_temporal_hour &lt;- dt_temporal_1 |&gt; group_by(Month, first_day_of_month, Crash_Hour) |&gt; summarise(total_accidents = n())\n\n\n# Distribution of total number of accidents by month (the total number of accidents is with the total within in Year-Month combination)\nplot_month &lt;- ggplot(dt_temporal_month |&gt; mutate(Month = as.factor(Month))) +\n  geom_boxplot(mapping = aes(x = total_accidents, y = Month)) +\n  geom_density_ridges(mapping = aes(x = total_accidents, y = Month),\n                      alpha = 0.4, fill = \"cornflowerblue\") +\n  theme_minimal() +\n  labs(subtitle = \"By month\")\n\n# Distribution of total number of accidents by Day of week (the total number of accidents is with the total within in Year-Month combination)\nplot_weekday &lt;- ggplot(dt_temporal_month) +\n  geom_boxplot(mapping = aes(x = total_accidents, y = Week_day)) +\n  geom_density_ridges(mapping = aes(x = total_accidents, y = Week_day),\n                      alpha = 0.4, fill = \"cornflowerblue\") +\n  theme_minimal() +\n  labs(subtitle = \"By weekday\")\n\n\n\n\nCode\n# Distribution of total number of accidents by Hour (the total number of accidents is with the total within in Year-Month combination)\n\nplot_hours &lt;- ggplot(dt_temporal_hour |&gt; mutate(Crash_Hour = as.factor(Crash_Hour))) +\n  geom_boxplot(mapping = aes(x = total_accidents, y = Crash_Hour)) +\n  geom_density_ridges(mapping = aes(x = total_accidents, y = Crash_Hour),\n                      alpha = 0.4, fill = \"cornflowerblue\") +\n  theme_minimal()\n# combined_plots &lt;- plot_month + plot_weekday + plot_hours\n\n# Combine the plots side by side with one common title\ncombined_plots &lt;- plot_month + plot_weekday +\n  plot_layout(ncol = 1, heights = c(2, 1)) +\n  plot_annotation(title = \"Distribution of total number of accidents\")\n\n# Print the combined plots\nprint(combined_plots)\n\n\nPicking joint bandwidth of 12.3\n\n\nPicking joint bandwidth of 9.83\n\n\n\n\n\nCode\nplot_hours + labs(title = \"Distribution of total number of accidents by day-hour\")\n\n\nPicking joint bandwidth of 3.2\n\n\n\n\n\n\nBy combining histograms and density plots, we gain valuable insights into the distribution of total accidents aggregated by months per year, examining variations across different months, weekdays, and day-hours\nNumber of accidents per month: Analyzing the density plots reveals a similar distribution in the total number of accidents across different months. However, delving into boxplots exposes distinct variances; for instance, the interquartile range (IQR) for January is significantly wider than that of February.\nNumber of accidents per weekday: The density plots unveil noticeable differences in the distribution of total accidents between weekends and weekdays, providing insights into the varying patterns throughout the week.\nNumber of accidents per Hour in day: Exploring the density plots illustrates significant disparities in the distribution of total accidents across different times of the day. During the night time, there is a lower disparity in the number of accidents, making predictions more manageable. On the contrary, daytime accidents exhibit higher disparity, suggesting that factors beyond the time of day play a significant role. Identifying predictors, such as holidays, could be useful in preventing unnecessary accidents. Notably, it confirms the increase in accidents during the middle of the day, aligning with the expected higher traffic volumes during those hours."
  },
  {
    "objectID": "results.html#part-2---hitrun-analyis",
    "href": "results.html#part-2---hitrun-analyis",
    "title": "3  Results",
    "section": "3.2 Part 2 - Hit/run Analyis",
    "text": "3.2 Part 2 - Hit/run Analyis\nIn this part we addresses the pressing issue of hit-and-run accidents. We examine correlation between various features and the “Hit-Run” column. Hit and Run accidents involve perpetrators who attempt to flee the scene without taking responsibility for the consequences of their actions. Identifying patterns in the behavior of these accidents could assist the police in reducing the proportion of such incidents.\n\n\nCode\ndt_temporal_Year_month_hit_run &lt;- dt_temporal |&gt; group_by(Year, Month, first_day_of_month, Week_day, Hit_Run) |&gt; summarise(total_accidents = n())\n\ndt_temporal_Year_month_hit_run &lt;- dt_temporal |&gt; group_by(Year, Month, first_day_of_month, Week_day, Hit_Run) |&gt; summarise(total_accidents = n())\n\n\n\n3.2.1 Is it more likely to Hit and Run in a specific Month / Week day / Hour?\n\n\nCode\n# Filter out NA values for Hit_Run\nfiltered_data &lt;- dt_temporal %&gt;%\n  filter(!is.na(Hit_Run))\n\n# Abbreviate the Month and Weekday names\nmonth_labels &lt;- c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\")\nweekday_labels &lt;- c(\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\")\n\n# Divide the crash hour into groups\nfiltered_data$Crash_Hour_Group &lt;- cut(filtered_data$Crash_Hour,\n  breaks = c(0, 4, 8, 12, 16, 20, 24),\n  labels = c(\"0-4\", \"4-8\", \"8-12\", \"12-16\", \"16-20\", \"20-24\"),\n  include.lowest = TRUE)\n\nplot_month &lt;- ggplot(filtered_data) +\n\n  geom_bar(aes(x = Month, fill = Hit_Run), position = \"fill\", color = \"grey40\") +\n  scale_fill_manual(values = c(\"No\" = \"grey84\", \"Yes\" = \"lightgreen\")) +\n  labs(title = \"Proportion of Hit-Run Accidents\",\n       subtitle = \"Per Month of Year\",\n       x = \"Month\",\n       y = \"Proportion\") +\n  scale_x_discrete(labels = month_labels) +  # Abbreviate Month names\n  theme_minimal() +\n  theme(legend.position = \"none\")  # Remove the legend\n\n# Create a bar plot for Weekday\nplot_weekday &lt;- ggplot(filtered_data) +\n  geom_bar(aes(x = Week_day, fill = Hit_Run), position = \"fill\", color = \"grey40\") +\n  scale_fill_manual(values = c(\"No\" = \"grey84\", \"Yes\" = \"lightgreen\")) +\n  labs(subtitle = \"Per Weekday\",\n       x = \"Weekday\") +\n  scale_x_discrete(labels = weekday_labels) +  # Abbreviate Weekday names\n  theme_minimal() +\n  theme(legend.position = \"none\", axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank())  # Remove y-axis components\n\n\n\nplot_hours &lt;- ggplot(filtered_data) +\n  geom_bar(aes(x = Crash_Hour_Group, fill = Hit_Run), position = \"fill\", color = \"grey40\") +\n  labs(subtitle = 'Per Hour',\n       x = \"Crash Hour\", y = NULL) +\n  scale_fill_manual(values = c(\"No\" = \"grey84\", \"Yes\" = \"lightgreen\")) +\n  theme_minimal() +\n  theme(legend.position = \"none\", axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank())  # Remove y-axis components\n\n\n\n# Arrange the two plots side by side\ncombined_plot &lt;- plot_month + plot_weekday + plot_hours +  theme(legend.position = \"bottom\") \n\n# Print the combined plot\nprint(combined_plot)\n\n\n\n\n\n\nThere doesn’t appear to be a correlation between the month and Hit-Run incidents; in other words, there isn’t a particular month with a higher likelihood of a Hit-Run accident.\nHowever, we observe a higher proportion of Hit-Run incidents during weekends (Saturday and Sunday) compared to the proportions on other weekdays.\nConcerning the Hit-Run proportion per hour, we can observe there is a higher proportion of Hit-Run accidents during late hours. Furthermore, there seems to be a consistent “linear trend” in Hit-Run incidents as the day unfolds.\n\n\n\n3.2.2 Analyzing First_Harmful_Event with respect to Hit_Run\n\n\nCode\n#count(dt_temporal, First_Harmful_Event) |&gt; arrange(desc(n))\n\n### taking only the 7 top categories in  First_Harmful_Event\ndf_for_harmful_event &lt;- dt_temporal %&gt;%\n  filter(!is.na(First_Harmful_Event)) %&gt;%  # Remove NA values\n  mutate(\n    First_Harmful_Event = tolower(First_Harmful_Event),\n    First_Harmful_Event = factor(First_Harmful_Event) %&gt;% fct_lump(n = 7, other_level = \"Other\"))\n\n###Mosaic plot 1:\nmosaicplot(table(factor(df_for_harmful_event$First_Harmful_Event), df_for_harmful_event$Hit_Run), main= \"Mosaic plot for Hit Run vs First Harmful Event\",\n           color = c(rgb(0.5,0.5,0.5, alpha = 0.5), rgb(0,1,0, alpha = 0.5)), \n           las = 1)  # Rotate labels by 90 degrees\n\n\n\n\n\nCode\n#count(df_for_harmful_event, Hit_Run, First_Harmful_Event)\n\n\n\nWe can see that the first harmful event has a great connection / correlation to the Hit-Run variable –&gt; there are great variations between the proportion of Hit-Run vs. Non Hit-Run accidents given the different First_Harmful_Event categories.\nNote that for “Parked-Vehicle” the proportion of Hit-Run is 0.45 which is more than twice as big as the overall Hit-Run proportion (0.18):\n\n\n\nCode\n# Calculate the proportion of Hit/Run in the dataset\n\ndf_for_harmful_event |&gt; count(Hit_Run) |&gt; mutate(\"prop\" = n/nrow(dt_temporal))\n\n\n# A tibble: 3 × 3\n  Hit_Run     n      prop\n  &lt;chr&gt;   &lt;int&gt;     &lt;dbl&gt;\n1 No      77429 0.810    \n2 Yes     17524 0.183    \n3 &lt;NA&gt;        2 0.0000209\n\n\nCode\na &lt;- df_for_harmful_event |&gt; filter(grepl(c(\"Parked\"), First_Harmful_Event, ignore.case = T)) |&gt; count(Hit_Run, First_Harmful_Event) \na|&gt; mutate(\"prop\" = n/sum(a$n)) \n\n\n# A tibble: 2 × 4\n  Hit_Run First_Harmful_Event     n  prop\n  &lt;chr&gt;   &lt;fct&gt;               &lt;int&gt; &lt;dbl&gt;\n1 No      parked vehicle       4995 0.542\n2 Yes     parked vehicle       4215 0.458\n\n\n\n\nCode\n# Create a data set of interest\ndt_responsible &lt;- data_crash[,c(\"Hit_Run\",\"NonTraffic\",\"ACRS_Report_Type\")]\n\n\n# Rename the element in \"ACRS_Report_Type\"\ndt_responsible &lt;- dt_responsible %&gt;%\n   mutate(ACRS_Report_Type = recode(ACRS_Report_Type,\n    \"Injury Crash\" =\"Injury\",\n    \"Fatal Crash\" = \"Fatal\",\n    \"Property Damage Crash\" = \"Property Damage\")) %&gt;%\n    filter(ACRS_Report_Type != \"Fatal\")\n\n# Rename the element in \"ACRS_Report_Type\"\ndt_responsible &lt;- dt_responsible %&gt;%\n   mutate(Traffic = recode(NonTraffic,\n    \"Yes\" =\"No\",\n    \"No\" = \"Yes\"))%&gt;%\n  select(-NonTraffic)\n\n#redav::plot_missing(dt_responsible) # We see that more than 80% of the rows does not have Na so I will drop all the Na\n\ndt_responsible &lt;- dt_responsible %&gt;%\n  na.omit() \n\nvcd:: mosaic(Hit_Run ~ ACRS_Report_Type + Traffic ,\n data = dt_responsible,\n direction = c(\"v\", \"v\" ,\"h\"),\n highlighting_fill = c(\"grey84\", \"lightgreen\"))\n\n\n\n\n\n\nThis mosaic plots highlights 2 main trends about Hit and Run incidents. First, the proportion of hit and run is higher when nobody was injured. This correlates with the previous results about the parked vehicle in the first harmful event column. More people tend to flee when there is just material damage.\nThe second insight is that drivers tend to flee more when there is no traffic. Two conclusions can be made, either drivers feel less pressure to stop and report the damage done when there is no traffic or maybe it is simply easier to leave the incident location when there is no traffic.\nThese two insights help us understand better the driver’s behavior in the case of Hit and Run. However, this does not help us prevent these type of incidents. So in the following part we will explore the correlation between the characteristics of the roads and the number of Hit and Run accidents in order to give meaning full advice for reducing the proportion of these incidents.\n\n\n\n3.2.3 Study of the influence of the characteristics of the roads on the number of accident and Hit/Run\n\n\nCode\n## Create 2 new datasets to explore different Categorical values\ndt_lane &lt;- data_crash[,c(\"Road_Division\", \"Junction\", \"Road_Alignment\" ,\"Traffic_Control\",\"Road_Name\",\"Cross_Street_Name\",\"Number_of_Lanes\",\"Hit_Run\",\"Longitude\",'Latitude')]\n\n#Rename the column in Road_type and get rid of the Na and the unknown values\ndt_lane &lt;- dt_lane %&gt;%\n  mutate(Road_Division = recode(Road_Division,\n        \"TWO-WAY, NOT DIVIDED WITH A CONTINUOUS LEFT TURN\" = \"2-way, not divided\",\n        \"TWO-WAY, NOT DIVIDED\" = \"2-way, not divided\",\n        \"TWO-WAY, DIVIDED, POSITIVE MEDIAN BARRIER\" = '2-way, divided',\n        \"TWO-WAY, DIVIDED, UNPROTECTED PAINTED MIN 4 FEET\" = '2-way, divided',\n        \"ONE-WAY TRAFFICWAY\" = '1-way',\n        \"OTHER\" = 'Other')) %&gt;%\n  filter(Road_Division != 'UNKNOWN') %&gt;%\n  filter(Road_Division != 'Other') %&gt;%\n  na.omit()\n\n# #Change the column Number of Lanes to remove the lanes with more than 6 lanes\n# dt_lane &lt;- dt_lane %&gt;%\n#   filter(Number_of_Lanes &lt; 7) %&gt;%\n#   filter(Number_of_Lanes != 0)\n#   \n# # Change the order of factor \n# dt_lane$Road_Division &lt;- factor(dt_lane$Road_Division, levels = c(\"1-way\", \"2-way, not divided\", \"2-way, divided\", 'Other'))\n# \n# \n# ggplot(dt_lane, aes(y=Road_Division))+\n#   geom_bar() +\n#   facet_grid(Number_of_Lanes~.)+\n#   #theme(axis.text.x = element_text(angle = 45, hjust = 1))+\n#   labs(title ='Facet by number of Lanes' )\n# &lt;u&gt;Comment :&lt;/u&gt; One can see that most of the accidents that happends on 3 lanes road are 2-way and divided (most likely highway). \n\n#Traffic Control\n\ndt_lane &lt;- dt_lane %&gt;%\n   mutate(Traffic_Control = recode(Traffic_Control,\n        \"FLASHING TRAFFIC SIGNAL\" = \"Traffic Light\",\n        \"TRAFFIC SIGNAL\" = \"Traffic Light\",\n        \"NO CONTROLS\" = 'No Sign',\n        \"RAILWAY CROSSING DEVICE    \" = 'Warning Sign',\n        \"WARNING SIGN\" = 'Warning Sign',\n        \"SCHOOL ZONE SIGN DEVICE\" = 'Warning Sign',\n        \"YIELD SIGN\" = 'Warning Sign',\n        \"STOP SIGN\" = 'Stop Sign',\n        .default  = 'Other')) %&gt;%\n  filter(!is.na(Traffic_Control))\n\nlane_freq &lt;- dt_lane %&gt;%\n  count(Traffic_Control, name = \"Frequency_control\")\ndt_lane &lt;- left_join(lane_freq, dt_lane, by = \"Traffic_Control\")\n  \n# ggplot(dt_lane, aes(x = reorder(Traffic_Control, -Frequency_control))) +\n#   geom_bar() +\n#   labs(title = \"Bar Plot of Junction Types with Count\", x = \"Junction Type\", y = \"Count\") +\n#   theme_minimal()  # Adjust the theme if needed\n\n\n\n3.2.3.1 Insight about accidents around intersection\nFirst, let’s observe the typical situation in which accidents occur :\n\n\nCode\ndt_lane &lt;- dt_lane %&gt;%\n  mutate(Junction = recode(Junction,\n        \"INTERSECTION\" = \"Intersection\",\n        \"INTERSECTION RELATED\" = \"Intersection\",\n        \"NON INTERSECTION\" = 'Non Intersection',\n        \"OTHER DRIVEWAY\" = 'Driveway',\n        \"COMMERCIAL DRIVEWAY\" = 'Driveway',\n        \"ALLEY\" = 'Driveway',\n        \"CROSSOVER RELATED\" = \"Crossover\",\n        \"INTERCHANGE RELATED\" = \"Interchange\",\n        \"RESIDENTIAL DRIVEWAY\" = 'Driveway',\n        \"RAILWAY GRADE CROSSING\"= 'Other',\n        \"OTHER\" = 'Other')) %&gt;%\n  filter(Junction != 'UNKNOWN') %&gt;%\n  filter(Junction != 'Other') %&gt;%\n  na.omit() \n\nlane_freq &lt;- dt_lane %&gt;%\n  count(Junction, name = \"Frequency_junc\")\ndt_lane_freq &lt;- left_join(lane_freq, dt_lane, by = \"Junction\")\n\nggplot(dt_lane_freq, aes(x = reorder(Junction, -Frequency_junc))) +\n  geom_bar(aes(fill = Traffic_Control)) +\n  labs(title = \"Relation between Junction Types and Traffic Control sign\", x = \"Junction Type\", y = \"Count\", fill = \"Signalisation for Traffic\") +\n  scale_fill_viridis_d() +\n  theme_minimal()  \n\n\n\n\n\n\nWe can observe that most of the car accidents happen at an intersection. Further, half of the crashes at these intersection have traffic lights. This highlights an important issue : traffic light are not sufficient to mitigate the risk of car accident. The data set provides the name of the intersection so we can explore the proportion of intersections with traffic light and compare that to the proportion of accidents happening at an intersection with traffic light. So in the next plot we will compare these two proportions.\n\n\n\nCode\n# Calculate the total number of unique intersection\ntotal_combinations_intersec &lt;- dt_lane_freq %&gt;%\n  filter(Junction == \"Intersection\") %&gt;%\n  summarise(total_combinations_count = n_distinct(paste(Cross_Street_Name, Road_Name, sep = \"_\")))\n\n# Calculate the number of unique intersection with a traffic light\nwith_traffic_light &lt;- dt_lane_freq %&gt;%\n  filter(Junction == \"Intersection\") %&gt;%\n  filter(Traffic_Control == \"Traffic Light\") %&gt;%\n  summarise(with_traffic_light_count = n_distinct(paste(Cross_Street_Name, Road_Name, sep = \"_\")))\n\n# Calculate the proportion\nproportion_with_traffic_light &lt;- with_traffic_light$with_traffic_light_count / total_combinations_intersec$total_combinations_count\n\n#print(paste(\"Proportion of Intersection with Traffic Light: \", proportion_with_traffic_light))\n\n\nggplot(dt_lane_freq %&gt;% filter(Junction == 'Intersection'), aes(x = reorder(Junction, -Frequency_junc), fill = Traffic_Control)) +\n  geom_bar(position = \"fill\", width = 0.6) +\n  labs(\n    title = \"Proportion of accident on intersection depending on the signalisation\",\n    subtitle = paste0(\"Knowing that \", round(proportion_with_traffic_light * 100,1), \"% of the intersection has a traffic light\"),\n    x = \"Junction Type\",\n    y = \"Proportion\",\n    fill = \"Signalisation for Traffic\"\n  ) +\n  scale_fill_viridis_d() +\n  theme_minimal()+\n  coord_flip()+\n   theme(aspect.ratio = 0.4)\n\n\n\n\n\nDespite not having the proportion of number of cars crossing intersection with traffic light vs the number of car crossing intersection without traffic light this histogram seems to indicate that traffic light are not efficient enough for reducing car accident. Indeed, even though there are less than 40% of intersection with traffic lights in the county, overall more than 60% of the accidents occur at these intersection. A possible reason is that drivers rely too much on the traffic light and do not proceed to do the safety check when crossing an intersection. NB: In this study we focus only on the number of accidents and not on the fluidity of the traffic for instance. Needless to say that reducing the number of accidents cannot be the only factor to consider when designing traffic sign on the roads.\n\n\n3.2.3.2 Alluvial plot to understand Hit/Run pattern\n\n\nCode\ndt_lane1 &lt;- dt_lane[,c('Road_Division', 'Junction', 'Traffic_Control','Road_Name','Hit_Run')]\n\nn_threshold = 100 \ndt_lane1 &lt;- dt_lane1 %&gt;%\n  group_by(Road_Division, Junction, Traffic_Control) %&gt;%\n  mutate(Frequency = n()) %&gt;%\n  ungroup() %&gt;%\n  filter(Frequency &gt;= n_threshold) %&gt;%\n  distinct(Road_Division, Junction, Traffic_Control, .keep_all = TRUE)\n\n# Map_pt &lt;- dt_lane1$Road_Name\n# Map_pt\n\njunction_order &lt;- c(\"Crossover\", \"Intersection\", \"Driveway\",\"Non Intersection\", \"Interchange\")\n\n# Reorder the Junction variable in the dataset\ndt_lane1 &lt;- dt_lane1 %&gt;%\n  mutate(Junction = factor(Junction, levels = junction_order))\n\n# Plot the alluvial diagram\n\nggplot(data = dt_lane1,\n       aes(axis1 = Road_Division, axis2 = Traffic_Control, axis3 = Junction, axis4= Hit_Run, y = Frequency)) +\n  geom_alluvium(aes(fill = Hit_Run)) +\n  geom_stratum() +\n  geom_text(stat = \"stratum\",\n            aes(label = after_stat(stratum))) +\n  #scale_x_discrete(limits = c(\"Road Division\", \"Traffic Signal\", \"Junction type\"),\n                   #expand = c(0.15, 0.05, 0.05)) +\n  scale_fill_brewer(type = \"seq\", palette = \"PuRd\") +\n  labs(title = 'Alluvial plot combining characteristics about the crash location and the Hit/Run situation', fill= 'Hit/Run')+\n  theme_void()\n\n\n\n\n\nThe alluvial plots assist us in visualizing the most common scenarios leading to Hit & Run incidents. Indeed, the majority of these incidents occur on undivided two-way roads at non-intersections with no traffic controls. This visible pattern in the scenario of Hit/Run can be used to understand how the police could reduce this type of incidents. Without inferring causation from these correlation results, one might consider that the absence of traffic signs could potentially contribute to a sense of impunity among certain drivers, leading them to flee more frequently, assuming they are not being observed. For a more in-depth examination of this pattern, we would suggest law enforcement conduct a targeted study specifically focusing on roads without traffic signs to determine whether their presence has an impact on the occurrence of hit and run incidents. It’s important to note that these findings are purely correlational; other factors, such as accident severity, may play a role. If our dataset included a severity column, we could have explored this aspect further."
  },
  {
    "objectID": "results.html#part-3---spatial-representation",
    "href": "results.html#part-3---spatial-representation",
    "title": "3  Results",
    "section": "3.4 Part 3 - Spatial Representation",
    "text": "3.4 Part 3 - Spatial Representation\nWe employ geographical, or spatial, data to explore the relationship between accident density and geographical attributes. Specifically, we aim to identify roads with the highest concentration of accidents and analyze common attributes among them.\n\n\nCode\n## We are removing the data points which are not in the county\n\n# 1st step : get the coordinate of the Montgomery county using a public data\nmontgomery_geojson_url &lt;- 'https://raw.githubusercontent.com/johan/world.geo.json/master/countries/USA/MD/Montgomery.geo.json'\nmontgomery_county &lt;- st_read(montgomery_geojson_url)\n\n\nReading layer `Montgomery.geo' from data source \n  `https://raw.githubusercontent.com/johan/world.geo.json/master/countries/USA/MD/Montgomery.geo.json' \n  using driver `GeoJSON'\nSimple feature collection with 1 feature and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -77.5172 ymin: 38.9336 xmax: -76.8874 ymax: 39.3553\nGeodetic CRS:  WGS 84\n\n\nCode\n# 2nd step : Filter the data to keep only the Hit/Run incidents\nhit_run_pos &lt;- data_crash %&gt;%\n  filter(Hit_Run == 'Yes')\n  \n# Create a new dataset with only the coordinate of points inisde the county\ncoordinate_Montgomery &lt;- hit_run_pos %&gt;%\n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) %&gt;%\n  st_intersection(montgomery_county) %&gt;%\n  st_coordinates() %&gt;%\n  as.data.frame()\n\nleaflet(coordinate_Montgomery) %&gt;%\n  addTiles() %&gt;% \n  addHeatmap(\n  lat = ~Y,\n  lng = ~X,\n  blur = 15,  # Adjust the blur parameter\n  radius = 10) # Adjust the radius parameter\n\n\n\n\n\n\nCode\n  #addControl(title = \"Density of Hit/Run accidents\", position = \"topright\")\n\n\n\nOne key element that can be taken from that interactive map is that parking are place with high density of Hit/Run incidents. This correlate with one of our previous mosaic plot that displayed the ‘First_Harmful_Event’ column. We saw there that the “Parked-Vehicle” is the category with the highest proportion of Hit/Run.\nMoreover, it is visible that intersections are location with higher density of hit and run accidents. Overall, this heat map help us visualize the patterns we have discovered earlier, it is clear that there is almost no Hit/Run incidents on highway like 15A."
  },
  {
    "objectID": "results.html#overall-findings-from-plots-we-didnt-include-in-this-project",
    "href": "results.html#overall-findings-from-plots-we-didnt-include-in-this-project",
    "title": "3  Results",
    "section": "3.5 Overall findings from plots we didn’t include in this project:",
    "text": "3.5 Overall findings from plots we didn’t include in this project:\nOther than the plots we presented in this section, we created dozens more visualizations that were less informative thus excluded from the final report. However, we would like to highlight some of the findings and insights we derived from them.\n\n\nCode\ndt_temporal &lt;- dt_temporal %&gt;%\n  filter(!Weather %in% c(\"OTHER\", \"UNKNOWN\")) %&gt;%\n  filter(!is.na(Weather))\n\ndt_temporal &lt;- dt_temporal %&gt;%\n  mutate(Weather = if_else(Weather %in% c(\"SNOW\", \"SLEET\",\"BLOWING SNOW\"), \"SNOW\", Weather)) %&gt;%\n  mutate(Weather = if_else(Weather %in% c(\"SEVERE WINDS\", \"WINTRY MIX\", \"BLOWING SAND, SOIL, DIRT\"), \"WIND\", Weather))%&gt;%\n  mutate(Condition = if_else(Weather %in% c(\"CLEAR\",\"CLOUDY\"),\"Good\",\"Bad\"))\n\n# color_scale &lt;- c(\"RAINING\" = \"slateblue\", \"SNOW\" = \"whitesmoke\", \"CLOUDY\" = \"gray\", \"FOGGY\" =\"gray27\", \"WIND\"=\"seagreen4\", \"CLEAR\" =\"skyblue\")\n# \n# dt_temporal$Weather &lt;- reorder(dt_temporal$Weather, X= as.numeric(factor(dt_temporal$Weather,levels = c('CLEAR','CLOUDY','FOGGY','WIND','SNOW','RAINING'))))\n# \n# ggplot(dt_temporal, aes(x = Condition, fill = Weather)) +\n#   geom_bar() +\n#   scale_fill_manual(values = color_scale)\n\n\n\nWeather data: We define an accident that occurred with “good” weather conditions as an accident that the value in the column Weather was “CLEAR” or “CLOUDY”. The other condition types are classified as “Bad”. We analyzed the number of accidents in “Good” versus “Bad” weather conditions and found there are more accidents on days with “good” weather condition. The issue with that analysis is we don’t have the overall proportion of “good” vs. “bad” days. Our assumption is there are more “good” than “bad” days, and therefore, the fact there are more accidents on “good” days, doesn’t really mean anything.\nWe checked and there doesn’t seem to be a correlation between the Weather and the Hit_Run\n\n\n\nCode\n# df_mosaic_by_weather &lt;- dt_temporal |&gt; group_by(Weather, Hit_Run) |&gt; summarise(Freq = n())\n# \n# ###Mosaic plot 1:\n# mosaicplot(table(dt_temporal$Weather, dt_temporal$Hit_Run), main= \"Mosaic plot for Hit Run vs First Harmful Event\", color = c('tomato', 'darkgreen'), las = 2)  # Rotate labels by 90 degrees\n\n\n\n\nCode\n# ### Speaking about Roads, where are we ?\n# \n# dt_lane2 &lt;- dt_lane %&gt;%\n#   group_by(Road_Name) %&gt;%\n#   mutate(Frequency_road = n()) %&gt;%\n#   ungroup() %&gt;%\n#   #filter(Frequency &gt;= n_threshold) %&gt;%\n#   distinct(Road_Name, .keep_all = TRUE)\n# \n# top_10_roads &lt;- dt_lane2 %&gt;%\n#   arrange(desc(Frequency_road)) %&gt;%  # Arrange by Frequency in descending order\n#   slice_head(n = 10) %&gt;%       # Select the top 10 rows\n#   select(Road_Name,Frequency_road) %&gt;%\n#   as.list()\n# \n# top10 &lt;- top_10_roads$Road_Name\n# top10\n\n\n\nTime-plot displaying the total number of accidents trend over the years faceted by weekdays:\n\nIn the faceted line graph, a consistent trend is apparent in the number of accidents per weekday, suggesting a similar pattern across the week. However, the magnitude of accidents varies, with fewer incidents occurring on weekends, which aligns with expectations. Notably, the middle of the week appears to experience a higher frequency of accidents.\nFurthermore, an examination of the “black dots,” representing each year’s month with the highest number of accidents, provides additional insights. Comparing these dots across different weekdays reveals distinctions, and an intriguing observation emerges when connecting these dots. If we were to draw a line connecting each black dot, a trend similar to the loess blue line trend in the plot becomes evident, indicating a potential overarching pattern in the occurrence of maximum accidents over the years.\n\n\n\n\nCode\n## Filter the highest point in each Year\n# highest_points &lt;- dt_temporal_Year_month %&gt;%\n#   group_by(Year, Week_day) %&gt;%\n#   slice_max(order_by = total_accidents)\n# \n# ggplot(dt_temporal_Year_month, aes(x=first_day_of_month, y=total_accidents)) + \n#   geom_line() + \n#   stat_smooth(method = \"loess\", span=0.63, col = \"blue\", size = 1, se = FALSE) +  # Add a moving average line\n#   geom_point(data = highest_points, col = \"black\", size = 1.4) +  # Add points only for Jan\n#   facet_grid(~Week_day) +\n#   labs(title = \"line plot of total accidents faceted by weekday\",\n#        subtitle = \"The black dots present for each year the month with \\nthe highest number of accidents\")\n\n\n\nInfluence of Substances:\n\nWe also wanted to explore the affect of taking substance on the the number of accidents and Hit and Run. In most of the car accidents no substance were detected, the second highest number of accidents was made under the effect of alcohol. Then, the next category is called ‘unknown’. At first we thought it was related to accidents in which testing the substance was forgotten however by looking at the correlation with Hit/Run we saw an suprisingly high proportion of Hit and Run for this category. So despite having more information about this category we assumed that in most of these accidents the driver was not found leading to a lack of information about whether or not they consumed any substance. Furthermore, there was no significant difference in proportions among the various substances when examining hit and run incidents. Similarly we didn’t see any important trend when looking at who is at fault in the accident. The large majority of the time, the driver is at fault. However, there is a slight decrease of accident for which the non driver is not at fault when the driver took substance ; the proportion drop from 10% to 2% but it is not worth interpreting it further more.\n\n\nCode\ndt_responsible &lt;- data_crash[,c(\"At_Fault\",\"Driver_Substance_Abuse\")]\n# Rename the elements in \"Driver_Substance_Abuse\" and filter the Na\ndt_responsible &lt;- dt_responsible %&gt;%\n  mutate(Driver_Substance_Abuse = str_extract(Driver_Substance_Abuse, \"^[^,]+\")) %&gt;%\n  mutate(Driver_Substance_Abuse = recode(Driver_Substance_Abuse,\n    \"ALCOHOL CONTRIBUTED\" =\"alcohol\",\n    \"ALCOHOL PRESENT\" = \"alcohol\",\n    \"COMBINATION CONTRIBUTED\" = \"combined substance\",\n    \"COMBINED SUBSTANCE PRESENT\" = \"combined substance\",\n    \"ILLEGAL DRUG CONTRIBUTED\" = \"illegal drug\",\n    \"ILLEGAL DRUG PRESENT\" = \"illegal drug\",\n    \"MEDICATION CONTRIBUTED\" = \"under medication\",\n    \"MEDICATION PRESENT\" = \"under medication\",\n    \"UNKNOWN\" = 'unknown',\n    \"OTHER\" = 'unknown',\n    \"NONE DETECTED\" = 'none detected'\n  )) %&gt;%\n  filter(Driver_Substance_Abuse != \"N/A\")\n\ndt_responsible &lt;- dt_responsible %&gt;%\n  #filter(Driver_Substance_Abuse != 'none detected')  %&gt;% # remove the none detected because they are too much\n  #filter(Driver_Substance_Abuse != 'alcohol') %&gt;%\n  filter(Driver_Substance_Abuse != 'unknown')\n\nresponsible_freq &lt;- dt_responsible %&gt;%\n  count(Driver_Substance_Abuse, name = \"Frequency_drug\")\ndt_responsible &lt;- left_join(responsible_freq, dt_responsible, by = \"Driver_Substance_Abuse\")\n  \n# ggplot(dt_responsible, aes(x = reorder(Driver_Substance_Abuse, -Frequency_drug))) +\n#   geom_bar() +\n#   labs(title = \"Bar Plot of Junction Types with Count\", x = \"Junction Type\", y = \"Count\") +\n#   theme_minimal()  # Adjust the theme if needed\n# \n# vcd::mosaic(At_Fault ~ Driver_Substance_Abuse,\n#              data = dt_responsible,\n#   direction = c(\"v\", \"h\" ))"
  },
  {
    "objectID": "d3graph.html",
    "href": "d3graph.html",
    "title": "4  Interactive graph",
    "section": "",
    "text": "D3 Scatter Plot with Lines\n\n\n\n\n\n\n\nAverage number of car accidents per day of month over the years\n\n\nClick on the month buttons to display each one in the plot. You can also hover on the different points to see the average number of car accidents in those days.\n\n\n\n\n\n\n\n\n\n\n\n\nThe interactive visualization can help us compare the average number of accidents between the different months. For example if we click on months: February and December, you can see that, on average, most of December days have higher average accidents than February. Moreover you can see a sharp decrease on the 24-25 of December, which is reasonable as this is the Christmas holiday and less people drive in those days. Moreover, we can see that some months have small variance between the different day values - for example: September, October and May. There are other months, like July, with higher variance in the average number of daily accidents. You can try different combinations of months to derive those interesting insights.\n\n\nOverall, this interactive graph simplifies a crowded graph by reducing visual overload."
  },
  {
    "objectID": "data.html#nas-in-multiple-columns-columns-that-tend-to-have-nas-in-the-same-time",
    "href": "data.html#nas-in-multiple-columns-columns-that-tend-to-have-nas-in-the-same-time",
    "title": "2  Data",
    "section": "2.5 NAs in multiple columns –> columns that tend to have NAs in the same time",
    "text": "2.5 NAs in multiple columns –&gt; columns that tend to have NAs in the same time\nWe want to get a list of columns that have the same “NA” pattern:\n\n\nCode\nb &lt;- apply(data_crash, 2, function(c) sum(is.na(c)))\ntibble_nas_data_crash &lt;- tibble(column_name = names(b), number_of_NA = b)\n\n#Compare the 2 lists, the one with all the column with less that 1000 NAs and the lists with the same conditions but after removing all the NAs row in the column \"Cross-Street Type\"\na &lt;- tibble_nas_data_crash |&gt; filter(number_of_NA&lt;1000)\nb &lt;- tibble_nas_filtered_data_crash |&gt; filter(number_of_NA&lt;1000)\n\n# Get the name of the column which are not in common in the 2 previous list\ndifference_both_ways &lt;- union(setdiff(a$column_name, b$column_name), setdiff(b$column_name, a$column_name))\nprint(difference_both_ways)\n\n\n [1] \"Route_Type\"           \"Mile_Point\"           \"Mile_Point_Direction\"\n [4] \"Lane_Direction\"       \"Direction\"            \"Distance\"            \n [7] \"Distance_Unit\"        \"Road_Grade\"           \"Road_Name\"           \n[10] \"Cross_Street_Type\"    \"Cross_Street_Name\"    \"Road_Alignment\"      \n\n\nWe want to use the plot_missing function from the redav package to see the NA pattern regarding the columns that we suspect have NA in the same rows:\n\n\nCode\nredav::plot_missing(data_crash |&gt;dplyr::select(difference_both_ways,))\n\n\n\n\n\nUsing the plot_missing function and looking at the second row of the main plot, we can see that the most common NA pattern, that is visible in almost 25% of the rows, is the one where there is an NA value in all of the specified columns:\n\n\nCode\nprint(difference_both_ways)\n\n\n [1] \"Route_Type\"           \"Mile_Point\"           \"Mile_Point_Direction\"\n [4] \"Lane_Direction\"       \"Direction\"            \"Distance\"            \n [7] \"Distance_Unit\"        \"Road_Grade\"           \"Road_Name\"           \n[10] \"Cross_Street_Type\"    \"Cross_Street_Name\"    \"Road_Alignment\"      \n\n\nwe can clearly see that those columns indeed have NA in the same rows. We can conclude that their NAs are correlated.\nFurther, we will take one of those columns: Cross_Street_Type and use it as a representative of the 12 columns group and then see if there is any pattern between the NAs of the other columns:\n\n\nCode\nb &lt;- apply(data_crash, 2, function(c) sum(is.na(c)))\ntibble_nas &lt;- tibble(column_name = names(b), number_of_NA = b)\n\n\ncolumns_with_na &lt;- tibble_nas |&gt; filter(number_of_NA&gt;500) \n\ncolumns_with_na &lt;- columns_with_na$column_name\n\ndifferences &lt;- union(setdiff(columns_with_na, difference_both_ways), setdiff(difference_both_ways, columns_with_na))\n\ndifferences &lt;- c(differences, \"Cross_Street_Type\")\nprint(differences)\n\n\n [1] \"Weather\"                \"Surface_Condition\"      \"Light\"                 \n [4] \"Traffic_Control\"        \"Driver_Substance_Abuse\" \"First_Harmful_Event\"   \n [7] \"Junction\"               \"Road_Condition\"         \"Road_Division\"         \n[10] \"Cross_Street_Type\"     \n\n\nCode\nredav::plot_missing(data_crash |&gt;dplyr::select(differences,))\n\n\n\n\n\nWe can see that there is no common pattern between all the NAs for these 10 columns.\nIn conclusion, for all the columns in the array difference_both_ways we can deal with the NAs in the same way in the future. However, for the other columns which still have a lot of NA values, like Weather or Traffic Control, we need to be more careful when removing the NAs because we could end up with very few rows in the data set. We will take care of them on a case-by-case basis.\n\n2.5.0.1 Saving the updated data so we can read it in the “results” tab\n\n\nCode\nwrite_csv2(data_crash, \"data/data_crash.csv\")"
  }
]